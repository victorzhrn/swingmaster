# Pro Video Trajectory Implementation Plan - Minimal Version

## Core Principle: Each Pro Video = 1 Shot

### Overview
Pro videos are single shots. When comparing, play user's selected shot alongside the pro shot. Maximum simplicity.

---

## Phase 1: Pre-Processing (One-Time Setup)

### 1.1 Create Processing Script
**New File:** `Tools/ProcessProVideos.swift`

```swift
import Foundation
import AVFoundation

private struct BundledAnalysis: Codable {
    let videoFileName: String
    let duration: Double
    let shots: [Shot]
}

@main
struct ProcessProVideos {
    static func main() async throws {
        let apiKey = ProcessInfo.processInfo.environment["GEMINI_API_KEY"] ?? ""
        precondition(!apiKey.isEmpty, "GEMINI_API_KEY is required")

        try await processOne(inputPath: "/path/to/federer_forehand.mov",
                             outputPath: "/path/to/federer_forehand.analysis.json",
                             geminiAPIKey: apiKey)
        try await processOne(inputPath: "/path/to/nadal_backhand.mov",
                             outputPath: "/path/to/nadal_backhand.analysis.json",
                             geminiAPIKey: apiKey)
    }

    private static func processOne(inputPath: String, outputPath: String, geminiAPIKey: String) async throws {
        let url = URL(fileURLWithPath: inputPath)
        let processor = VideoProcessor(geminiAPIKey: geminiAPIKey)
        let results = await processor.processVideo(url)

        let duration = AVAsset(url: url).duration.seconds
        let shots: [Shot] = results.map { res in
            let t = (res.segment.startTime + res.segment.endTime) / 2.0
            return Shot(
                id: res.id,
                time: t,
                type: res.swingType,
                startTime: res.segment.startTime,
                endTime: res.segment.endTime,
                segmentMetrics: res.segmentMetrics,
                paddedPoseFrames: res.segment.frames,
                paddedObjectFrames: res.objectFrames
            )
        }

        let payload = BundledAnalysis(videoFileName: url.lastPathComponent, duration: duration, shots: shots)
        let data = try JSONEncoder().encode(payload)
        try data.write(to: URL(fileURLWithPath: outputPath), options: .atomic)
        print("Wrote: \(outputPath) shots=\(shots.count)")
    }
}
```

---

## Phase 2: Loading Pro Analysis

### 2.1 Simple Pro Video Loader
**New File:** `Managers/ProVideoLoader.swift` (30 lines)

```swift
import Foundation

enum ProVideoLoader {
    static func loadShot(named baseName: String) -> Shot? {
        struct BundledAnalysis: Codable { let videoFileName: String; let duration: Double; let shots: [Shot] }
        guard let url = Bundle.main.url(forResource: baseName, withExtension: "analysis.json"),
              let data = try? Data(contentsOf: url),
              let payload = try? JSONDecoder().decode(BundledAnalysis.self, from: data) else { return nil }
        return payload.shots.first
    }
}
```

---

## Phase 3: Display Integration

### 3.1 Minimal AnalysisView Changes
**Modify:** `AnalysisView.swift`

```swift
// In AnalysisView state
@State private var proShot: Shot?
@State private var proTrajectories: [TrajectoryType: [TrajectoryPoint]] = [:]
@State private var proVideoAspectRatio: CGFloat = 16.0/9.0

// Keep pro trajectories in sync with selection changes, mirroring user side
.onChange(of: enabledTrajectories) { _, _ in
    if isComparing, let shot = proShot {
        var map = proTrajectories
        for t in enabledTrajectories where map[t] == nil {
            map[t] = TrajectoryComputer.compute(
                type: t,
                poseFrames: shot.paddedPoseFrames,
                objectFrames: shot.paddedObjectFrames,
                startTime: shot.startTime,
                options: trajectoryOptions
            )
        }
        proTrajectories = map
    }
}

// Load on compare toggle
.onChange(of: isComparing) { _, newValue in
    if newValue {
        proShot = ProVideoLoader.loadShot(named: "DjokvicForhand")
        if let proURL = Bundle.main.url(forResource: "DjokvicForhand", withExtension: "mov") {
            loadProAspectRatio(from: proURL)
        }
        if let shot = proShot {
            var map: [TrajectoryType: [TrajectoryPoint]] = [:]
            for t in enabledTrajectories {
                map[t] = TrajectoryComputer.compute(
                    type: t,
                    poseFrames: shot.paddedPoseFrames,
                    objectFrames: shot.paddedObjectFrames,
                    startTime: shot.startTime,
                    options: trajectoryOptions
                )
            }
            proTrajectories = map
        }
    } else {
        proShot = nil
        proTrajectories = [:]
    }
}

private func loadProAspectRatio(from url: URL) { /* same as loadVideoAspectRatio, dispatched via Task */ }
```

### 3.2 Ultra-Simple Time Sync
**Modify:** `AnalysisView.swift`

```swift
// Computed mapping; binds into the right-hand player's currentTime
private var proVideoTime: Double {
    guard let userShot = shots.first(where: { $0.id == selectedShotID }),
          let pro = proShot else { return 0 }
    let userOffset = max(0, currentTime - userShot.startTime)
    return pro.startTime + userOffset
}
```

### 3.3 Split View Update
**Modify:** `AnalysisView.swift` - videoLayer function

```swift
HStack(spacing: 1) {
    // LEFT: User video (+ overlay)
    VideoPlayerView(
        url: url,
        currentTime: $currentTime,
        isPlaying: $isPlaying,
        showsControls: false,
        segmentStart: playingSegment?.startTime,
        segmentEnd: playingSegment?.endTime
    )
    .frame(width: geometry.size.width / 2)
    .clipped()
    .overlay(userVideoLabel, alignment: .topLeading)
    .overlay({
        if let shot = shots.first(where: { $0.id == selectedShotID }) {
            TrajectoryOverlay(
                trajectoriesByType: trajectoryCache[shot.id] ?? [:],
                enabledTrajectories: enabledTrajectories,
                currentTime: currentShotRelativeTime(shot: shot),
                shotDuration: max(0, shot.endTime - shot.startTime),
                videoAspectRatio: videoAspectRatio
            )
        }
    }(), alignment: .center)

    // RIGHT: Pro video (+ overlay)
    if let proURL = Bundle.main.url(forResource: "DjokvicForhand", withExtension: "mov") {
        VideoPlayerView(
            url: proURL,
            currentTime: .constant(proVideoTime),
            isPlaying: $isPlaying,
            showsControls: false
        )
        .frame(width: geometry.size.width / 2)
        .clipped()
        .overlay(proVideoLabel, alignment: .topLeading)
        .overlay({
            if let pro = proShot {
                TrajectoryOverlay(
                    trajectoriesByType: proTrajectories,
                    enabledTrajectories: enabledTrajectories,
                    currentTime: max(0, proVideoTime - pro.startTime),
                    shotDuration: max(0, pro.endTime - pro.startTime),
                    videoAspectRatio: proVideoAspectRatio
                )
            }
        }(), alignment: .center)
    }
}
```

---

## File Changes Summary

### New Files (2)
1. `Tools/ProcessProVideos.swift` - Dev tool (not shipped)
2. `Managers/ProVideoLoader.swift` - 30 lines

### Modified Files (1)
1. `AnalysisView.swift` - Add 2 state vars, 1 onChange, update split view

### Bundled Resources
- `federer_forehand.mov` - 2-3 second clip
- `federer_forehand.analysis.json` - JSON with `videoFileName`, `duration`, `shots: [Shot]`
- Optional: `nadal_backhand.mp4` + analysis
- Optional: `djokovic_serve.mp4` + analysis

---

## Implementation Steps

### Step 1: Prepare Pro Videos (30 min)
1. Trim pro videos to single shots (2-3 seconds each)
2. Ensure good quality and framing

### Step 2: Pre-Process (1 hour)
1. Create `ProcessProVideos.swift`
2. Set `GEMINI_API_KEY` in your env and run the processing tool on each pro video
3. Verify analysis files have 1 shot with good pose data

### Step 3: Runtime Loading (1 hour)
1. Create minimal `ProVideoLoader`
2. Add 2 state variables to AnalysisView
3. Load pro shot when compare toggles on

### Step 4: Display (2 hours)
1. Update split view with pro video
2. Add pro trajectory overlay
3. Implement simple time sync (direct offset)

### Integration Steps in AnalysisView (Checklist)
1. Add state: `proShot`, `proTrajectories`, `proVideoAspectRatio`.
2. On compare toggle `.onChange`, load pro shot via `ProVideoLoader.loadShot(named:)` and compute trajectories per enabled type using `TrajectoryComputer.compute(...)`.
3. Compute `proVideoTime` as `pro.startTime + max(0, currentTime - user.startTime)`.
4. In split view, bind right-player `currentTime: .constant(proVideoTime)`, `isPlaying: $isPlaying`.
5. Overlay `TrajectoryOverlay` on both sides with correct `shotDuration` and aspect ratios.

---

## Ultra-Minimal Sync Logic

```pseudo
// That's it. This is all the sync logic needed:
User plays from 1.2s to 3.2s of their video (a 2-second shot)
Pro plays from 0.0s to 2.0s of their video (their full shot)

Both controlled by the same isPlaying state
Both progress at the same rate; pro currentTime = pro.startTime + (userCurrent - user.startTime)
No complex phase matching needed
```

---

## Key Simplifications from Previous Version

1. **No shot matching** - Pro video IS the shot
2. **No shot selection for pro** - Always play the one shot
3. **No duration normalization** - Just play both at natural speed
4. **No phase detection** - Simple time offset
5. **No caching logic** - Load once when comparing starts
6. **No pro shot array** - Single shot variable

---

## Notes and Corrections vs Codebase

- `TrajectoryOverlay` API: `trajectoriesByType: [TrajectoryType: [TrajectoryPoint]]`, plus `shotDuration` and `videoAspectRatio`. Build trajectories using `TrajectoryComputer.compute(...)` per enabled type.
- Bundle and decode `shots: [Shot]` in a small wrapper JSON. Do not try to decode `AnalysisResult` from disk; it is not Codable in the app.
- `VideoProcessor` must be initialized with `geminiAPIKey`.
- `VideoPlayerView` binds `currentTime` and `isPlaying`; using `.constant(proVideoTime)` is a valid way to sync the pro clip to the userâ€™s segment.

## Edge Cases Handled Automatically

- **Different shot durations**: Both play their natural duration
- **User changes shots**: Pro always plays its one shot from start
- **Trajectory timing**: Each uses its own relative time
- **Play/pause**: Single isPlaying controls both

---

## Testing Checklist

- [ ] Pro video loads and plays
- [ ] Trajectory appears on pro video
- [ ] Play/pause affects both videos
- [ ] Trajectory toggles work on both sides
- [ ] Time sync feels natural
- [ ] Memory usage acceptable

---

## Future Options (Not MVP)

1. **Multiple pro shots**: Let user choose which pro shot type
2. **Speed matching**: Option to slow pro video to match user
3. **Loop mode**: Repeat both shots continuously

---

## Estimated Effort

- **Total: 4-5 hours**
- 30 min: Video preparation
- 1 hour: Pre-processing setup
- 1 hour: Loading logic
- 2 hours: UI integration
- 30 min: Testing

This approach is approximately **70% simpler** than the previous version while delivering the same user value.