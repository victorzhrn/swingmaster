# Tennis Swing Trajectory Visualization - Complete Implementation Plan

## Current Issues Found in Codebase

1. **Shot model updated**: MockShot has been renamed to Shot throughout codebase
2. **Object detection not implemented**: `processVideoWithObjects` returns empty object frames
3. **Wrong frame rate**: Using 10fps instead of 30fps
4. **No swing padding**: Swings may be cut off at boundaries
5. **No trajectory computation**: Missing entirely from the codebase

## Architecture Overview (MVP Minimal Refactor)

```mermaid
flowchart TB
    subgraph "Data Processing Layer (native FPS)"
        VP[VideoProcessor] --> PF[PoseFrames]
        PF --> SD[SwingDetector]
        SD -->|Detects| PS[PotentialSwings]
        PS --> GV[GeminiValidator]
        GV -->|Validates| VS[ValidatedSwings]
        VS --> PM[ProcessingManager]
        PM --> AS[AnalysisStore]
        AS -->|Persists| SHOTS[Shots (MVP)]
    end

    subgraph "UI Computation Layer (On-Demand)"
        SHOTS --> AV[AnalysisView]
        AV --> ODH[On-Demand Object Detection\n(TennisObjectDetector.detectObjects(in:start:end:))]
        AV --> TC[TrajectoryComputer]
        TC -->|Gap Filling| GF[Up to ~0.33s]
        GF -->|Smoothing| SM[3-point moving average]
        SM --> TPs[TrajectoryPoints]
        TPs --> TO[TrajectoryOverlay]
        AV --> TTS[TrajectorySelector]
        TTS -->|Toggles| TC
    end
    
    style VP fill:#4A9B4E
    style TC fill:#F7DC6F
    style GF fill:#FF6B6B
    style SM fill:#4169E1
    style TO fill:#E67E22
```

## 1. Data Models (MVP)

For MVP, persistence remains `shots` in `AnalysisStore`. Trajectories are computed on-demand.

```swift
// Reuse existing ObjectDetection models
struct RacketDetection { let boundingBox: CGRect; let confidence: Float; let timestamp: TimeInterval }
struct BallDetection   { let boundingBox: CGRect; let confidence: Float; let timestamp: TimeInterval }
struct ObjectDetectionFrame { let timestamp: TimeInterval; let racket: RacketDetection?; let ball: BallDetection? }
```

## 2. Fix Video Processing Pipeline (Native FPS + Object Detection)

```swift
// Core/VideoProcessor.swift - CRITICAL FIXES (align with native FPS)

private func processVideoWithObjects(_ url: URL) async -> ([PoseFrame], [ObjectDetectionFrame]) {
    // Detect native FPS from the file; fall back if unavailable
    let videoFPS = getVideoFPS(from: url) ?? 10.0
    logger.log("[File] Using video FPS: \(videoFPS, format: .fixed(precision: 1))")

    // Extract poses at native FPS via PoseProcessor (uses internal stride)
    let poseFrames = await poseProcessor.processVideoFile(url, targetFPS: videoFPS) { [weak self] p in
        Task { @MainActor in self?.state = .extractingPoses(progress: p) }
    }

    // Run object detection for file frames to align with pose timestamps
    // Implementation approach:
    // - Iterate the video frames with AVAssetReader (BGRA)
    // - For each frame, get timestamp and run objectDetector.detectObjects
    // - Map to ObjectDetectionFrame using existing models (ObjectDetection.swift)
    // - Optionally filter by confidence > 0.3
    // Note: Keep this aligned with poseFrames ordering and timestamps.

    var objectFrames: [ObjectDetectionFrame] = []
    // Placeholder until implemented; align empty detections to pose timestamps
    objectFrames = poseFrames.map { frame in
        ObjectDetectionFrame(timestamp: frame.timestamp, racket: nil, ball: nil)
    }

    return (poseFrames, objectFrames)
}

// NEW: Extract segment data with padding
private func extractSegmentData(
    swing: ValidatedSwing,
    allPoseFrames: [PoseFrame],
    allObjectFrames: [ObjectDetectionFrame]
) -> (poseFrames: [PoseFrame], objectFrames: [ObjectDetectionFrame], paddedSegment: SwingSegment) {
    
    let swingStart = swing.frames.first?.timestamp ?? 0
    let swingEnd = swing.frames.last?.timestamp ?? 0
    
    // Add 0.5 second padding to capture full motion
    let paddingSeconds = 0.5
    let paddedStart = swingStart - paddingSeconds
    let paddedEnd = swingEnd + paddingSeconds
    
    // Filter frames within padded window
    let relevantPoses = allPoseFrames.filter { 
        $0.timestamp >= paddedStart && $0.timestamp <= paddedEnd 
    }
    
    let relevantObjects = allObjectFrames.filter { 
        $0.timestamp >= paddedStart && $0.timestamp <= paddedEnd 
    }
    
    // Create padded segment
    let paddedSegment = SwingSegment(
        startTime: paddedStart,
        endTime: paddedEnd,
        frames: swing.frames  // Keep original validated frames
    )
    
    return (relevantPoses, relevantObjects, paddedSegment)
}

// Update processVideo to use native FPS and store raw data
public func processVideo(_ url: URL) async -> [AnalysisResult] {
    // ... existing swing detection ...
    
    // Analyze validated swings WITH raw segment data
    var results: [AnalysisResult] = []
    for (idx, swing) in validated.enumerated() {
        self.state = .analyzingSwings(current: idx + 1, total: validated.count)
        
        // Extract segment data with padding
        let (segmentPoses, segmentObjects, paddedSegment) = extractSegmentData(
            swing: swing,
            allPoseFrames: poseFrames,
            allObjectFrames: objectFrames
        )
        
        let segmentMetrics = metricsCalculator.calculateSegmentMetrics(for: swing.frames)
        
        if let analysis = try? await geminiValidator.analyzeSwing(swing, metrics: segmentMetrics) {
            // Create result with raw data
            let result = AnalysisResult(
                segment: paddedSegment,  // Use padded segment
                swingType: analysis.swingType,
                score: analysis.score,
                strengths: analysis.strengths,
                improvements: analysis.improvements,
                keyFrames: analysis.keyFrames,
                poseFrames: segmentPoses,      // Store segment poses
                objectFrames: segmentObjects    // Store segment objects
            )
            results.append(result)
        }
    }
    
    return results
}
```

## 3. On-Demand Trajectory Computer with Gap Filling & Smoothing

```swift
// Utils/TrajectoryComputer.swift - NEW FILE
import SwiftUI
import Vision

public struct TrajectoryPoint: Equatable {
    let x: Float        // Normalized 0-1
    let y: Float        // Normalized 0-1
    let timestamp: Double // Relative to shot start
    let confidence: Float
    let isInterpolated: Bool  // Track if this point was gap-filled
    
    init(x: Float, y: Float, timestamp: Double, confidence: Float, isInterpolated: Bool = false) {
        self.x = x
        self.y = y
        self.timestamp = timestamp
        self.confidence = confidence
        self.isInterpolated = isInterpolated
    }
}

public enum TrajectoryType: String, CaseIterable, Identifiable {
    case rightWrist = "Right Wrist"
    case leftWrist = "Left Wrist"
    case rightElbow = "Right Elbow"
    case leftElbow = "Left Elbow"
    case rightShoulder = "Right Shoulder"
    case leftShoulder = "Left Shoulder"
    case racketCenter = "Racket"
    case ballCenter = "Ball"
    
    public var id: String { rawValue }
    
    var color: Color {
        switch self {
        case .rightWrist, .leftWrist:
            return Color(hex: "#5CB85C") // Tennis green
        case .rightElbow, .leftElbow:
            return Color(hex: "#4169E1") // Royal blue
        case .rightShoulder, .leftShoulder:
            return Color(hex: "#FF6B6B") // Coral
        case .racketCenter:
            return Color(hex: "#F7DC6F") // Tennis yellow
        case .ballCenter:
            return Color(hex: "#FFD700") // Gold
        }
    }
    
    var icon: String {
        switch self {
        case .rightWrist, .leftWrist: return "hand.raised"
        case .rightElbow, .leftElbow: return "figure.arms.open"
        case .rightShoulder, .leftShoulder: return "person"
        case .racketCenter: return "tennisball"
        case .ballCenter: return "circle.fill"
        }
    }
}

public struct TrajectoryOptions {
    let fillGaps: Bool
    let maxGapFrames: Int  // Maximum gap to fill (in frames)
    let smooth: Bool
    let smoothingWindow: Int
    
    static let `default` = TrajectoryOptions(
        fillGaps: true,
        maxGapFrames: 10,  // At 30fps, 10 frames = 0.33 seconds
        smooth: true,
        smoothingWindow: 3
    )
}

public struct TrajectoryComputer {
    
    public static func computeTrajectory(
        type: TrajectoryType,
        poseFrames: [PoseFrame],
        objectFrames: [ObjectDetectionFrame],
        startTime: Double,
        options: TrajectoryOptions = .default
    ) -> [TrajectoryPoint] {
        
        // Extract raw points based on type
        var points: [TrajectoryPoint]
        
        switch type {
        case .rightWrist:
            points = extractJointTrajectory(.rightWrist, from: poseFrames, startTime: startTime)
        case .leftWrist:
            points = extractJointTrajectory(.leftWrist, from: poseFrames, startTime: startTime)
        case .rightElbow:
            points = extractJointTrajectory(.rightElbow, from: poseFrames, startTime: startTime)
        case .leftElbow:
            points = extractJointTrajectory(.leftElbow, from: poseFrames, startTime: startTime)
        case .rightShoulder:
            points = extractJointTrajectory(.rightShoulder, from: poseFrames, startTime: startTime)
        case .leftShoulder:
            points = extractJointTrajectory(.leftShoulder, from: poseFrames, startTime: startTime)
        case .racketCenter:
            points = extractRacketTrajectory(from: objectFrames, startTime: startTime)
        case .ballCenter:
            points = extractBallTrajectory(from: objectFrames, startTime: startTime)
        }
        
        // Apply gap filling if enabled
        if options.fillGaps && points.count > 1 {
            points = fillGaps(in: points, maxGapFrames: options.maxGapFrames)
        }
        
        // Apply smoothing if enabled
        if options.smooth && points.count > options.smoothingWindow {
            points = smoothTrajectory(points, windowSize: options.smoothingWindow)
        }
        
        return points
    }
    
    // MARK: - Extraction Methods
    
    private static func extractJointTrajectory(
        _ joint: VNHumanBodyPoseObservation.JointName,
        from frames: [PoseFrame],
        startTime: Double
    ) -> [TrajectoryPoint] {
        return frames.compactMap { frame in
            guard let point = frame.joints[joint],
                  let confidence = frame.confidences[joint],
                  confidence > 0.3 else { return nil }
            
            return TrajectoryPoint(
                x: Float(point.x),
                y: Float(point.y),
                timestamp: frame.timestamp - startTime,
                confidence: confidence
            )
        }
    }
    
    private static func extractRacketTrajectory(
        from frames: [ObjectDetectionFrame],
        startTime: Double
    ) -> [TrajectoryPoint] {
        return frames.compactMap { frame in
            guard let racket = frame.racket,
                  racket.confidence > 0.3 else { return nil }
            
            return TrajectoryPoint(
                x: Float(racket.boundingBox.midX),
                y: Float(racket.boundingBox.midY),
                timestamp: frame.timestamp - startTime,
                confidence: racket.confidence
            )
        }
    }
    
    private static func extractBallTrajectory(
        from frames: [ObjectDetectionFrame],
        startTime: Double
    ) -> [TrajectoryPoint] {
        return frames.compactMap { frame in
            guard let ball = frame.ball,
                  ball.confidence > 0.3 else { return nil }
            
            return TrajectoryPoint(
                x: Float(ball.boundingBox.midX),
                y: Float(ball.boundingBox.midY),
                timestamp: frame.timestamp - startTime,
                confidence: ball.confidence
            )
        }
    }
    
    // MARK: - Gap Filling (up to 10 frames at 30fps)
    
    private static func fillGaps(in points: [TrajectoryPoint], maxGapFrames: Int) -> [TrajectoryPoint] {
        guard points.count > 1 else { return points }
        
        var filled: [TrajectoryPoint] = []
        filled.append(points[0])
        
        // Estimate frame interval from timestamps; fall back to 1/30 if unknown
        let frameInterval = estimateFrameInterval(points: points) ?? (1.0 / 30.0)
        
        for i in 1..<points.count {
            let prev = points[i-1]
            let curr = points[i]
            let timeDiff = curr.timestamp - prev.timestamp
            let frameGap = Int((timeDiff / frameInterval).rounded()) - 1
            
            if frameGap > 0 && frameGap <= maxGapFrames {
                // Linear interpolation for gaps up to maxGapFrames
                for j in 1...frameGap {
                    let t = Float(j) / Float(frameGap + 1)
                    let interpolated = TrajectoryPoint(
                        x: prev.x + (curr.x - prev.x) * t,
                        y: prev.y + (curr.y - prev.y) * t,
                        timestamp: prev.timestamp + Double(j) * frameInterval,
                        confidence: min(prev.confidence, curr.confidence) * 0.7,
                        isInterpolated: true  // Mark as interpolated
                    )
                    filled.append(interpolated)
                }
            }
            
            filled.append(curr)
        }
        
        return filled
    }
    
    // MARK: - Smoothing (3-point moving average)
    
    private static func smoothTrajectory(_ points: [TrajectoryPoint], windowSize: Int = 3) -> [TrajectoryPoint] {
        guard points.count > windowSize else { return points }
        
        var smoothed: [TrajectoryPoint] = []
        
        for i in 0..<points.count {
            let startIdx = max(0, i - windowSize/2)
            let endIdx = min(points.count - 1, i + windowSize/2)
            
            var sumX: Float = 0
            var sumY: Float = 0
            var count: Float = 0
            
            for j in startIdx...endIdx {
                sumX += points[j].x
                sumY += points[j].y
                count += 1
            }
            
            smoothed.append(TrajectoryPoint(
                x: sumX / count,
                y: sumY / count,
                timestamp: points[i].timestamp,
                confidence: points[i].confidence,
                isInterpolated: points[i].isInterpolated
            ))
        }
        
        return smoothed
    }

    // Heuristic: median delta of successive timestamps for stability
    private static func estimateFrameInterval(points: [TrajectoryPoint]) -> Double? {
        let deltas = zip(points.dropFirst(), points.dropLast(0)).map { (curr, prev) in
            curr.timestamp - prev.timestamp
        }.filter { $0 > 0 }
        guard !deltas.isEmpty else { return nil }
        let sorted = deltas.sorted()
        let mid = sorted.count / 2
        if sorted.count % 2 == 0 {
            return (sorted[mid - 1] + sorted[mid]) / 2.0
        } else {
            return sorted[mid]
        }
    }
}
```

## 4. Update UI Components to Use AnalysisResult

### Fix AnalysisStore

```swift
// Managers/AnalysisStore.swift - UPDATE
struct PersistedAnalysis: Codable, Equatable {
    let videoFileName: String
    let duration: Double
    let results: [AnalysisResult]  // Changed from shots: [Shot]
}

enum AnalysisStore {
    static func save(videoURL: URL, duration: Double, results: [AnalysisResult]) {
        let fileName = videoURL.lastPathComponent
        var all = cache
        all[fileName] = PersistedAnalysis(
            videoFileName: fileName, 
            duration: duration, 
            results: results
        )
        persist(all)
        cache = all
    }
    
    // Load returns AnalysisResult array
    static func load(videoURL: URL) -> PersistedAnalysis? {
        let fileName = videoURL.lastPathComponent
        return cache[fileName]
    }
}
```

### Fix TimelineStripEnhanced

```swift
// Components/TimelineStripEnhanced.swift - UPDATE
struct TimelineStripEnhanced: View {
    let duration: Double
    let shots: [AnalysisResult]  // CHANGED from [Shot]
    @Binding var selectedShotID: AnalysisResult.ID?
    @Binding var currentTime: Double
    @Binding var isPlaying: Bool
    
    var onPlaySegment: ((AnalysisResult) -> Void)?
    var onPrev: (() -> Void)? = nil
    var onNext: (() -> Void)? = nil
    
    // Update all references:
    // shot.type → shot.swingType
    // shot.startTime → shot.segment.startTime
    // shot.endTime → shot.segment.endTime
    // shot.time → (shot.segment.startTime + shot.segment.endTime) / 2
}
```

### Fix AnalysisView

```swift
// Views/AnalysisView.swift - UPDATE
struct AnalysisView: View {
    let videoURL: URL?
    let duration: Double
    let shots: [AnalysisResult]  // CHANGED from [Shot]
    
    @State private var selectedShotID: AnalysisResult.ID?
    @State private var currentTime: Double = 0
    @State private var isPlaying: Bool = false
    @State private var playingSegment: AnalysisResult? = nil
    
    // NEW: Trajectory controls
    @State private var showTrajectoryMenu = false
    @State private var enabledTrajectories: Set<TrajectoryType> = [.rightWrist, .racketCenter]
    @State private var trajectoryOptions = TrajectoryOptions.default
    @State private var videoAspectRatio: CGFloat = 16.0/9.0
    
    // ... rest of implementation
}
```

## 5. Trajectory Overlay with Progressive Animation

```swift
// Components/TrajectoryOverlay.swift - NEW FILE
import SwiftUI
import AVFoundation

struct TrajectoryOverlay: View {
    let shot: AnalysisResult
    let currentTime: Double        // Relative to shot start
    let shotDuration: Double
    let videoAspectRatio: CGFloat
    let isPlaying: Bool
    let enabledTrajectories: Set<TrajectoryType>
    let options: TrajectoryOptions
    
    @State private var showFullPath = false
    @State private var trajectoryCache: [TrajectoryType: [TrajectoryPoint]] = [:]
    
    var body: some View {
        GeometryReader { geometry in
            Canvas { context, size in
                let videoRect = calculateVideoRect(viewSize: size, videoAspectRatio: videoAspectRatio)
                let progress = min(1.0, max(0, currentTime / shotDuration))
                let hasStarted = currentTime > 0.01
                let hasCompleted = progress >= 0.95 || showFullPath
                
                // Draw each enabled trajectory
                for type in enabledTrajectories {
                    let points = getOrComputeTrajectory(for: type)
                    
                    if !points.isEmpty {
                        drawTrajectory(
                            context: context,
                            points: points,
                            color: type.color,
                            videoRect: videoRect,
                            progress: progress,
                            showDotOnly: !hasStarted,
                            showFullPath: hasCompleted
                        )
                    }
                }
            }
        }
        .onAppear { precomputeTrajectories() }
        .onChange(of: enabledTrajectories) { _, _ in precomputeTrajectories() }
        .onChange(of: currentTime) { _, newTime in
            if newTime / shotDuration >= 0.95 {
                withAnimation(.easeInOut(duration: 0.3)) {
                    showFullPath = true
                }
            } else if newTime < 0.1 {
                showFullPath = false
            }
        }
    }
    
    private func calculateVideoRect(viewSize: CGSize, videoAspectRatio: CGFloat) -> CGRect {
        let viewAspectRatio = viewSize.width / viewSize.height
        
        var videoWidth: CGFloat
        var videoHeight: CGFloat
        
        if videoAspectRatio > viewAspectRatio {
            // Letterbox
            videoWidth = viewSize.width
            videoHeight = viewSize.width / videoAspectRatio
        } else {
            // Pillarbox
            videoHeight = viewSize.height
            videoWidth = viewSize.height * videoAspectRatio
        }
        
        let x = (viewSize.width - videoWidth) / 2
        let y = (viewSize.height - videoHeight) / 2
        
        return CGRect(x: x, y: y, width: videoWidth, height: videoHeight)
    }
    
    private func getOrComputeTrajectory(for type: TrajectoryType) -> [TrajectoryPoint] {
        if let cached = trajectoryCache[type] {
            return cached
        }
        
        let computed = TrajectoryComputer.computeTrajectory(
            type: type,
            poseFrames: shot.poseFrames,
            objectFrames: shot.objectFrames,
            startTime: shot.segment.startTime,
            options: options
        )
        
        trajectoryCache[type] = computed
        return computed
    }
    
    private func precomputeTrajectories() {
        trajectoryCache.removeAll()
        for type in enabledTrajectories {
            _ = getOrComputeTrajectory(for: type)
        }
    }
    
    private func drawTrajectory(
        context: GraphicsContext,
        points: [TrajectoryPoint],
        color: Color,
        videoRect: CGRect,
        progress: Double,
        showDotOnly: Bool,
        showFullPath: Bool
    ) {
        // Map normalized points to video rect coordinates
        let screenPoints = points.map { point in
            CGPoint(
                x: videoRect.minX + CGFloat(point.x) * videoRect.width,
                y: videoRect.minY + CGFloat(1.0 - point.y) * videoRect.height
            )
        }
        
        if showDotOnly {
            // Show starting position only
            if let start = screenPoints.first {
                drawStartDot(context: context, at: start, color: color)
            }
        } else if showFullPath {
            // Show complete path with interpolated segments
            drawCompletePath(context: context, 
                           points: zip(screenPoints, points).map { ($0, $1) }, 
                           color: color)
        } else {
            // Progressive drawing
            let visibleCount = max(1, Int(Double(points.count) * progress))
            let visibleScreenPoints = Array(screenPoints.prefix(visibleCount))
            let visibleDataPoints = Array(points.prefix(visibleCount))
            
            drawGrowingPath(context: context,
                          points: zip(visibleScreenPoints, visibleDataPoints).map { ($0, $1) },
                          color: color)
        }
    }
    
    private func drawStartDot(context: GraphicsContext, at point: CGPoint, color: Color) {
        // Pulsing effect
        context.fill(
            Circle().path(in: CGRect(x: point.x - 12, y: point.y - 12, width: 24, height: 24)),
            with: .color(color.opacity(0.2))
        )
        context.fill(
            Circle().path(in: CGRect(x: point.x - 4, y: point.y - 4, width: 8, height: 8)),
            with: .color(color)
        )
    }
    
    private func drawGrowingPath(
        context: GraphicsContext,
        points: [(CGPoint, TrajectoryPoint)],
        color: Color
    ) {
        guard points.count > 1 else {
            if let first = points.first {
                drawStartDot(context: context, at: first.0, color: color)
            }
            return
        }
        
        // Draw path segments with different styles for interpolated points
        for i in 1..<points.count {
            let prev = points[i-1]
            let curr = points[i]
            
            var path = Path()
            path.move(to: prev.0)
            path.addLine(to: curr.0)
            
            let strokeStyle: StrokeStyle
            if curr.1.isInterpolated {
                // Dashed line for interpolated segments
                strokeStyle = StrokeStyle(lineWidth: 2, dash: [4, 2])
            } else {
                // Solid line for actual detected points
                strokeStyle = StrokeStyle(lineWidth: 3)
            }
            
            context.stroke(
                path,
                with: .color(color.opacity(curr.1.isInterpolated ? 0.5 : 0.8)),
                style: strokeStyle
            )
        }
        
        // Current position dot
        if let current = points.last {
            context.fill(
                Circle().path(in: CGRect(x: current.0.x - 5, y: current.0.y - 5, width: 10, height: 10)),
                with: .color(color)
            )
        }
    }
    
    private func drawCompletePath(
        context: GraphicsContext,
        points: [(CGPoint, TrajectoryPoint)],
        color: Color
    ) {
        guard points.count > 1 else { return }
        
        // Draw complete path with visual distinction for interpolated segments
        for i in 1..<points.count {
            let prev = points[i-1]
            let curr = points[i]
            
            var path = Path()
            path.move(to: prev.0)
            path.addLine(to: curr.0)
            
            if curr.1.isInterpolated {
                // Interpolated segment - dashed and lighter
                context.stroke(
                    path,
                    with: .color(color.opacity(0.4)),
                    style: StrokeStyle(lineWidth: 2, dash: [4, 2])
                )
            } else {
                // Actual detected segment - solid
                context.stroke(
                    path,
                    with: .color(color.opacity(0.8)),
                    style: StrokeStyle(lineWidth: 3, lineCap: .round, lineJoin: .round)
                )
            }
        }
        
        // Start and end markers
        if let start = points.first {
            context.fill(
                Circle().path(in: CGRect(x: start.0.x - 3, y: start.0.y - 3, width: 6, height: 6)),
                with: .color(color.opacity(0.6))
            )
        }
        if let end = points.last {
            context.fill(
                Circle().path(in: CGRect(x: end.0.x - 4, y: end.0.y - 4, width: 8, height: 8)),
                with: .color(color)
            )
        }
    }
}
```

## 6. Trajectory Selection UI Component

```swift
// Components/TrajectorySelector.swift - NEW FILE
import SwiftUI

struct TrajectorySelector: View {
    @Binding var enabledTrajectories: Set<TrajectoryType>
    @Binding var trajectoryOptions: TrajectoryOptions
    @State private var isExpanded = false
    
    var body: some View {
        VStack(alignment: .trailing, spacing: 8) {
            // Main toggle button
            Button(action: { withAnimation { isExpanded.toggle() } }) {
                HStack(spacing: 6) {
                    Image(systemName: "scribble.variable")
                    if !enabledTrajectories.isEmpty {
                        Text("\(enabledTrajectories.count)")
                            .font(.caption)
                            .padding(.horizontal, 6)
                            .padding(.vertical, 2)
                            .background(Capsule().fill(Color.tennisGreen))
                            .foregroundColor(.white)
                    }
                }
                .padding(.horizontal, 12)
                .padding(.vertical, 8)
                .background(.regularMaterial)
                .clipShape(Capsule())
            }
            
            if isExpanded {
                VStack(alignment: .leading, spacing: 2) {
                    // Trajectory type toggles
                    ForEach(TrajectoryType.allCases) { type in
                        Button(action: { toggleTrajectory(type) }) {
                            HStack {
                                Image(systemName: type.icon)
                                    .frame(width: 20)
                                    .foregroundColor(type.color)
                                
                                Text(type.rawValue)
                                    .font(.system(size: 13))
                                
                                Spacer()
                                
                                if enabledTrajectories.contains(type) {
                                    Image(systemName: "checkmark")
                                        .font(.system(size: 11, weight: .bold))
                                        .foregroundColor(type.color)
                                }
                            }
                            .padding(.horizontal, 12)
                            .padding(.vertical, 8)
                            .contentShape(Rectangle())
                        }
                        .buttonStyle(PlainButtonStyle())
                    }
                    
                    Divider()
                        .padding(.vertical, 4)
                    
                    // Options toggles
                    VStack(alignment: .leading, spacing: 8) {
                        Toggle("Fill Gaps", isOn: Binding(
                            get: { trajectoryOptions.fillGaps },
                            set: { newValue in
                                trajectoryOptions = TrajectoryOptions(
                                    fillGaps: newValue,
                                    maxGapFrames: trajectoryOptions.maxGapFrames,
                                    smooth: trajectoryOptions.smooth,
                                    smoothingWindow: trajectoryOptions.smoothingWindow
                                )
                            }
                        ))
                        .font(.system(size: 12))
                        
                        Toggle("Smooth Path", isOn: Binding(
                            get: { trajectoryOptions.smooth },
                            set: { newValue in
                                trajectoryOptions = TrajectoryOptions(
                                    fillGaps: trajectoryOptions.fillGaps,
                                    maxGapFrames: trajectoryOptions.maxGapFrames,
                                    smooth: newValue,
                                    smoothingWindow: trajectoryOptions.smoothingWindow
                                )
                            }
                        ))
                        .font(.system(size: 12))
                    }
                    .padding(.horizontal, 12)
                    .padding(.vertical, 4)
                }
                .padding(.vertical, 8)
                .frame(width: 200)
                .background(.regularMaterial)
                .clipShape(RoundedRectangle(cornerRadius: 12))
            }
        }
    }
    
    private func toggleTrajectory(_ type: TrajectoryType) {
        if enabledTrajectories.contains(type) {
            enabledTrajectories.remove(type)
        } else {
            enabledTrajectories.insert(type)
        }
    }
}
```

## 7. Updated AnalysisView with Trajectories

```swift
// Views/AnalysisView.swift - COMPLETE UPDATE
struct AnalysisView: View {
    let videoURL: URL?
    let duration: Double
    let shots: [AnalysisResult]  // Real data!
    
    @State private var selectedShotID: AnalysisResult.ID?
    @State private var currentTime: Double = 0
    @State private var isPlaying: Bool = false
    @State private var playingSegment: AnalysisResult? = nil
    
    // Trajectory controls
    @State private var enabledTrajectories: Set<TrajectoryType> = [.rightWrist, .racketCenter]
    @State private var trajectoryOptions = TrajectoryOptions.default
    @State private var videoAspectRatio: CGFloat = 16.0/9.0
    
    private var currentShot: AnalysisResult? {
        shots.first(where: { $0.id == selectedShotID })
    }
    
    private var shotRelativeTime: Double {
        guard let shot = currentShot else { return 0 }
        return max(0, currentTime - shot.segment.startTime)
    }
    
    var body: some View {
        ScrollView {
            VStack(spacing: 12) {
                ZStack {
                    if let url = videoURL {
                        VideoPlayerView(
                            url: url,
                            currentTime: $currentTime,
                            isPlaying: $isPlaying,
                            segmentStart: playingSegment?.segment.startTime,
                            segmentEnd: playingSegment?.segment.endTime,
                            onSegmentComplete: { playingSegment = nil }
                        )
                        .onAppear { loadVideoAspectRatio(from: url) }
                        .overlay(
                            // Trajectory visualization
                            Group {
                                if let shot = currentShot,
                                   !shot.poseFrames.isEmpty {
                                    TrajectoryOverlay(
                                        shot: shot,
                                        currentTime: shotRelativeTime,
                                        shotDuration: shot.segment.endTime - shot.segment.startTime,
                                        videoAspectRatio: videoAspectRatio,
                                        isPlaying: isPlaying,
                                        enabledTrajectories: enabledTrajectories,
                                        options: trajectoryOptions
                                    )
                                    .allowsHitTesting(false)
                                }
                            }
                        )
                        .overlay(alignment: .topTrailing) {
                            // Trajectory controls
                            TrajectorySelector(
                                enabledTrajectories: $enabledTrajectories,
                                trajectoryOptions: $trajectoryOptions
                            )
                            .padding(12)
                        }
                    }
                }
                .frame(height: 320)
                // ... rest of video container styling
                
                // Timeline
                TimelineStripEnhanced(
                    duration: duration,
                    shots: shots,
                    selectedShotID: $selectedShotID,
                    currentTime: $currentTime,
                    isPlaying: $isPlaying,
                    onPlaySegment: { shot in playSegment(shot) },
                    onPrev: selectPrev,
                    onNext: selectNext
                )
                .padding(.horizontal, 16)
                
                // Insight card
                enhancedInsightCard
                    .padding(.horizontal, 16)
            }
        }
    }
    
    private func loadVideoAspectRatio(from url: URL) {
        Task {
            let asset = AVAsset(url: url)
            guard let track = try? await asset.loadTracks(withMediaType: .video).first else { return }
            
            let size = try? await track.load(.naturalSize)
            let transform = try? await track.load(.preferredTransform)
            
            guard let size = size else { return }
            
            let transformedSize = size.applying(transform ?? .identity)
            let width = abs(transformedSize.width)
            let height = abs(transformedSize.height)
            
            await MainActor.run {
                self.videoAspectRatio = width / height
            }
        }
    }
    
    private func playSegment(_ shot: AnalysisResult) {
        playingSegment = shot
        currentTime = shot.segment.startTime
        isPlaying = true
    }
    
    // Update navigation to use AnalysisResult
    private func selectPrev() {
        guard let id = selectedShotID, 
              let idx = shots.firstIndex(where: { $0.id == id }) else { return }
        let newIndex = max(idx - 1, 0)
        let shot = shots[newIndex]
        selectedShotID = shot.id
        playSegment(shot)
    }
    
    private func selectNext() {
        guard let id = selectedShotID, 
              let idx = shots.firstIndex(where: { $0.id == id }) else { return }
        let newIndex = min(idx + 1, shots.count - 1)
        let shot = shots[newIndex]
        selectedShotID = shot.id
        playSegment(shot)
    }
}
```

## 8. Update ProcessingManager

```swift
// Managers/ProcessingManager.swift - UPDATE
private func processVideo(session: Session, videoURL: URL, sessionStore: SessionStore) async {
    // ... existing setup ...
    
    let results = await processor.processVideo(videoURL)
    
    await MainActor.run {
        // Save real AnalysisResults with raw frame data
        let duration = VideoStorage.getDurationSeconds(for: session.videoURL)
        
        AnalysisStore.save(
            videoURL: session.videoURL,
            duration: duration,
            results: results  // Real AnalysisResult array with pose/object frames
        )
        
        sessionStore.updateSession(session.id) { session in
            session.shotCount = results.count
            session.processingStatus = .complete
        }
    }
}
```

## Implementation Checklist

- [ ] **Phase 1: Data Models**
  - [ ] Update `AnalysisResult` to include `poseFrames` and `objectFrames`
  - [ ] Create `ObjectDetectionFrame`, `RacketDetection`, `BallDetection`
  - [ ] Make `PoseFrame` Codable
  - [ ] Update `AnalysisStore` to use `AnalysisResult`

- [ ] **Phase 2: Video Processing**
  - [ ] Fix `processVideoWithObjects` to actually detect objects
  - [ ] Use native video FPS for file processing (dynamic detection)
  - [ ] Add `extractSegmentData` with 0.5s padding
  - [ ] Store raw frame data with each segment

- [ ] **Phase 3: Trajectory Computation**
  - [ ] Create `TrajectoryComputer` with gap filling
  - [ ] Implement gap filling up to ~0.33s based on estimated frame interval
  - [ ] Add 3-point moving average smoothing
  - [ ] Mark interpolated points for visual distinction

- [ ] **Phase 4: UI Updates**
  - [ ] Update `TimelineStripEnhanced` to use `AnalysisResult`
  - [ ] Update `AnalysisView` to use `AnalysisResult`
  - [ ] Create `TrajectoryOverlay` component
  - [ ] Create `TrajectorySelector` UI component
  - [ ] Update `VideoSessionCard` to use real data

- [ ] **Phase 5: Cleanup**
  - [x] Renamed MockShot to Shot (completed)
  - [x] Remove all MockShot references (completed)
  - [ ] Update `ProcessingManager`
  - [ ] Test complete flow

## Key Technical Details

### Frame Rate: Native FPS
- Use the file's native FPS for pose/object extraction (dynamic detection)
- Gap filling works up to ~0.33 seconds (based on estimated frame interval)
- Smooth trajectories at the native video rate

### Segment Padding: 0.5 seconds
- Captures approach and follow-through
- Ensures full swing is visible
- ~15 extra frames before/after at 30fps

### Visual Feedback
- Solid lines for detected points
- Dashed lines for interpolated gaps
- Progressive animation during playback
- Color coding for different trajectory types

### Performance
- Cache computed trajectories per shot
- Only compute enabled trajectory types
- ~90 frames per segment at 30fps
- Store raw data for future flexibility

This implementation uses the Shot model for compatibility, stores raw data for maximum flexibility, and provides smooth trajectory visualization with gap filling and user controls.