# Tennis App - Core Architecture & Implementation Guide

## Purpose & Audience

This guide is for architects and senior developers. It explains design intent, module responsibilities, and plain‑language contracts. It avoids code and focuses on how parts fit together and what they guarantee.

## System Overview

The app processes tennis swings from video (live or recorded) using Apple's Vision framework to detect body pose, analyzes motion patterns, and provides coaching feedback.

## Architecture at a Glance

Input → Processing Pipeline → Storage → UI

- Input: Camera capture and file import (triggered from MainView floating action button)
- Processing: Pose extraction → Object detection (YOLO11) → Swing detection → Contact point analysis → Metrics calculation
- Storage: Local media management, YOLO11 model bundle, and structured persistence
- UI: Single MainView dashboard with session cards, Analysis detail, Camera capture, and tennis-specific overlays

## File Structure

```
swingmaster/
├── Assets.xcassets/
├── DesignSystem/
│   ├── Colors.swift              # Color tokens & semantic colors (dark-mode aware)
│   ├── Typography.swift          # Type scale helpers & MetricStyle
│   ├── Spacing.swift             # 4pt grid spacing tokens
│   ├── Theme.swift               # Environment object (reduce motion/transparency)
│   └── Components/
│       ├── GlassContainer.swift  # Reusable glass-morphism container
│       └── TennisAvatar.swift    # Solid color avatar with initial
├── Components/
│   ├── TimelineStripEnhanced.swift   # Enhanced timeline with shot markers
│   ├── ViewModeControl.swift         # Unified view selector (Racket/Wrist/Skeleton/Off)
│   ├── CompareToggle.swift           # Explicit "Compare vs Pro" control with switch
│   ├── VideoPlayerView.swift
│   ├── SkeletonOverlay.swift         # Body pose visualization overlay
│   ├── BallOverlay.swift             # Tennis ball detection overlay
│   ├── RacketOverlay.swift           # Racket detection overlay
│   ├── VideoSessionCard.swift       # Video-primary session card with inline processing
│   ├── VideoProcessingOverlay.swift # Inline processing status overlay
│   ├── CoachCard.swift              # AI insight card
│   ├── CoachCardCarousel.swift      # Carousel for multiple coach cards
│   ├── WelcomeCoachCard.swift       # Welcome/onboarding coach card
│   ├── FloatingActionButton.swift   # Record/Upload trigger
│   ├── RecordOptionsModal.swift     # Action chooser (Record Now / Upload)
│   ├── MarkdownContent.swift        # Markdown content renderer
│   └── PageIndicator.swift          # Page navigation indicator
├── Managers/
│   ├── CameraManager.swift          # Enhanced with YOLO11 orientation handling
│   ├── SessionStore.swift           # Enhanced with ProcessingStatus tracking
│   ├── ProcessingManager.swift      # Singleton for background video processing
│   └── AnalysisStore.swift          # MVP persistence of analysis-by-video
├── Navigation/
│   └── NavigationState.swift       # Centralized navigation state management
├── Core/
│   ├── PoseProcessor.swift          # Human pose detection via Vision
│   ├── TennisObjectDetector.swift   # YOLO11-based ball/racket detection
│   ├── SwingDetector.swift          # Swing boundary detection
│   ├── MetricsCalculator.swift      # Kinematic metrics calculation
│   ├── GeminiValidator.swift        # Swing validation (AI analysis removed)
│   └── VideoProcessor.swift         # Orchestrates full processing pipeline
├── Mock/
│   └── MockCoachData.swift          # Mock coaching insights data
├── Models/
│   ├── PoseFrame.swift              # Normalized pose data with timestamps
│   ├── SwingSegment.swift           # Detected swing with boundaries
│   ├── AnalysisResult.swift         # Complete swing analysis results
│   ├── ObjectDetection.swift        # YOLO11 detection results (ball/racket)
│   ├── CoachInsight.swift           # AI coaching insight structure
│   ├── Shot.swift                   # Individual shot data
│   └── SessionSummary.swift         # Aggregated session data
├── Utils/
│   └── VideoStorage.swift          # Video file management with thumbnails
├── Views/
│   ├── MainView.swift               # Single scrollable dashboard (root)
│   ├── CameraView.swift             # Recording UI with real-time overlays
│   ├── AnalysisView.swift           # Complete analysis presentation
│   └── CoachDetailView.swift        # Unified coaching card detail view
├── yolo11l.mlpackage/               # YOLO11 CoreML model bundle
├── ContentView.swift
└── swingmasterApp.swift
```

## Module Responsibilities (by directory)

- DesignSystem
  - `Colors.swift`: Provides base palette (tennis greens/yellow/clay) and semantic colors; dynamic color variants for dark mode; hex initializers for `Color`/`UIColor`.
  - `Typography.swift`: Convenience functions for common text styles (`largeTitle`, `headline`, `metric`) and `MetricStyle` ViewModifier; encourages monospaced metrics to avoid layout shift.
  - `Spacing.swift`: 4pt grid design tokens (`micro` → `xxlarge`) and convenience constants (`cardPadding`, `screenMargin`, `sectionGap`).
  - `Theme.swift`: Environment-backed object exposing `colorScheme`, `useReducedTransparency`, and `useReduceMotion` for adaptive UI decisions.
  - `Components/GlassContainer.swift`: Standardized glass-morphism container with style presets (subtle/medium/heavy), bordered edges, and light-mode-only shadow.
  - `Components/TennisAvatar.swift`: Simple solid color avatar (no gradients) rendering the user's initial with tennis theme color.

- Core
  - `PoseProcessor.swift`: Extracts human pose from frames or video using Vision; normalizes coordinates; provides timestamped pose frames to downstream modules.
  - `TennisObjectDetector.swift`: YOLO11-based detection of tennis balls and rackets in video frames; handles device orientation and coordinate transformation; provides confidence-based filtering. Supports on-demand file-based detection for a time window. Avoids UIKit import to support CLI tools; optionally reads `YOLO11_MODEL_PATH` environment variable to locate a compiled `.mlmodelc` outside the app bundle.
  - `SwingDetector.swift`: Finds peaks in motion and extracts short candidate segments; emits `PotentialSwing`s rather than final segments.
  - `MetricsCalculator.swift`: Derives kinematic measures (e.g., wrist speed, contact point, body angles) and simplified swing paths; applies smoothing; integrates object detection data.
  - `GeminiValidator.swift`: Validation of `PotentialSwing`s using pose data (AI analysis features removed).
  - `VideoProcessor.swift`: Orchestrates end‑to‑end processing pipeline including pose extraction, object detection, swing detection, and metrics calculation for both live and file sources.

- Models
  - `PoseFrame.swift`: One frame of normalized pose data with joint confidences; the common currency for detection and metrics.
  - `SwingSegment.swift`: A detected swing with start/end times, type, constituent frames, and optional video linkage; the unit of analysis.
  - `AnalysisResult.swift`: The finalized outcome for a swing, including metrics and score; suitable for storage and display (AI insights removed).
  - `ObjectDetection.swift`: YOLO11 detection results containing bounding boxes, confidence scores, and object classifications for tennis balls and rackets.
  - `CoachInsight.swift`: Structured AI coaching insights with categories, recommendations, and markdown content for user guidance.
  - `Shot.swift`: Individual shot data. UI-agnostic by design (no `SwiftUI` imports or color mapping). Exposes `ShotType` with `shortLabel` and `accessibleName` for UI text and accessibility; any color mapping is provided via UI-layer extensions. Stores optional `keyFrameTimes` (absolute timestamps for Preparation, Backswing, Contact, Follow Through, Recovery) when available from validation.

- Components (UI)
  - `TimelineStripEnhanced.swift`: Enhanced 56‑point overlay timeline with shot markers; supports snap‑to‑nearest selection, haptics, and VoiceOver adjustability.
  - `ViewModeControl.swift`: Lightweight inline control that selects visualization mode (Racket Path, Wrist Path, Skeleton, Off). Binds directly to `enabledTrajectories` and `showSkeleton`, persists last choice with `@AppStorage`.
  - `CompareToggle.swift`: Inline switch labeled “Compare vs Pro” that enables side‑by‑side playback. Maintains independent play state for the pro video.
  - `SkeletonOverlay.swift`: Draws real‑time body skeleton from pose frames excluding facial joints; converts Vision coordinates to view space; animates lines between joints with confidence‑based coloring; handles device orientation.
  - `BallOverlay.swift`: Renders tennis ball detection bounding boxes from YOLO11 results; handles coordinate transformation and confidence-based visibility; provides real-time ball tracking visualization.
  - `RacketOverlay.swift`: Displays racket detection overlays with bounding boxes and confidence indicators; supports real-time tracking and coordinate transformation for accurate positioning.
  - `VideoProcessingOverlay.swift`: Non-blocking inline overlay showing processing status on video cards; displays progress for pose extraction, object detection, swing validation, and AI analysis stages; uses ultra-thin material background with status text.
  - `VideoSessionCard.swift`: Enhanced to show inline processing status using VideoProcessingOverlay; displays error states with retry functionality; maintains responsiveness during background processing.
  - `CoachCardCarousel.swift`: Horizontal scrollable carousel for displaying multiple coaching insights with page indicators and smooth navigation.
  - `WelcomeCoachCard.swift`: Onboarding and welcome card component for new users with tennis-themed styling and call-to-action guidance.
  - `MarkdownContent.swift`: Renders markdown-formatted coaching content with proper styling and interactive elements for comprehensive coaching insights.

- Managers & Storage
  - `SessionStore.swift`: Enhanced with ProcessingStatus enum tracking (pending, extractingPoses, detectingObjects, calculatingMetrics, detectingSwings, validatingSwings, complete, failed); supports updateSession for reactive state changes; manages session metadata with retry counts and error tracking.
  - `ProcessingManager.swift`: Singleton managing concurrent video processing tasks; limits to 2 concurrent operations; maintains queue for pending tasks; maps VideoProcessor states to Session.ProcessingStatus; handles retry logic with configurable max attempts (default: 3).
  - `CameraManager.swift`: Enhanced with YOLO11 orientation handling and real-time object detection integration; manages camera capture with pose and object detection overlays; adapts detection coordinates to device orientation.
  - `NavigationState.swift`: Centralized navigation state using NavigationPath; manages sheet presentations; provides push/pop methods for programmatic navigation; single source of truth for app navigation flow.
  - `AnalysisStore.swift` (MVP): Persists per‑video analysis results for `AnalysisView` via `UserDefaults`, keyed by video file name. Stores `duration` and `[Shot]` only. Intended as a temporary solution before Core Data.
  - `ProVideoLoader.swift` (MVP compare): Loads bundled pro-shot analysis JSON (`*.analysis.json`) and exposes the first `Shot` for side-by-side comparison.
  - `VideoStorage.swift`: Manages app‑owned video files (move from temp, delete, measure total size); enhanced with async thumbnail generation that returns file paths; supports retention policies; includes YOLO11 model bundle management.

- Views
  - `MainView.swift`: Single scrollable dashboard using design-system tokens. Profile header uses `TennisAvatar`; empty state uses `GlassContainer(.subtle)`; shows `CoachCardCarousel`, `WelcomeCoachCard`, and `VideoSessionCard` list with inline processing status. Floating action button overlays and opens `RecordOptionsModal` for Record/Upload.
  - `CameraView.swift`: Recording UI with real-time overlays including `SkeletonOverlay`, `BallOverlay`, and `RacketOverlay`; returns video URL to ContentView for immediate session creation and background processing; displays live pose and object detection feedback.
- `AnalysisView.swift`: Presents swing metrics with an enhanced bottom navigation consisting of `KeyframeTabs` (Preparation, Backswing, Contact, Follow Through, Recovery), `TimelineStripEnhanced`, and floating inline controls: `ViewModeControl` on the left and `CompareToggle` on the right. `KeyframeTabs` uses AI‑validated absolute keyframe timestamps from `Shot.keyFrameTimes` when present (via `GeminiValidator` → `VideoProcessor` → `ProcessingManager`), and falls back to proportional times if absent. Accessible when processing is complete; displays simple metrics from SegmentMetrics (AI insights removed). Pro comparison uses `ProVideoLoader`, keeps trajectories per enabled type in sync, and loosely time‑syncs playback by offset.
  - `CoachDetailView.swift`: Presents coaching insights using `GlassContainer(style: .medium, cornerRadius: 16)` with `MarkdownContent` for rich formatting; includes tag badges, titles, and comprehensive coaching guidance with tennis-specific recommendations.

- Utils
  - `FrameBuffer.swift`: Fixed‑size circular buffer for recent pose frames, optimized for constant‑time append and bounded memory.
  - `VideoStorage.generateThumbnail(for:at:)` supports timestamped thumbnails for `VideoSessionCard`.
- `TrajectoryComputer.swift`: On-demand trajectory computation (extraction, gap fill, smoothing) for joints/ball/racket used by the trajectory overlay. `ViewModeControl` selects which `TrajectoryType` is enabled.
  - Smoothing lives within `MetricsCalculator` and `TrajectoryComputer` in the MVP; a separate `SignalProcessor.swift` can be introduced later if needed.

## Interfaces & Contracts (plain language)

- `PoseProcessor`
  - Inputs: Camera frames or video files
  - Outputs: Ordered `PoseFrame`s with normalized coordinates and confidence values
  - Guarantees: Background execution for heavy work; consistent coordinate system; optional downsampling

- `TennisObjectDetector`
  - Inputs: Camera frames or video frames with device orientation
  - Outputs: `ObjectDetection`s with bounding boxes, confidence scores, and classifications for tennis balls and rackets
  - Guarantees: YOLO11-based detection with orientation-aware coordinate transformation; confidence-based filtering; real-time performance

- `SwingDetector`
  - Inputs: Time‑ordered `PoseFrame`s
  - Outputs: `PotentialSwing` candidates around velocity peaks (not final boundaries)
  - Guarantees: Bounded internal buffer; simple threshold‑based state machine; emits candidates with sufficient context for validation

- `GeminiValidator`
  - Inputs: `PotentialSwing`s (≈30 frames) and pose data
  - Outputs: Validated swings with refined start/end frames, swing type, confidence, and absolute `KeyFrameTimes` derived from key frame indices
  - Guarantees: Uses pose data for swing validation; network‑robust with retries and basic rate limiting (AI analysis features removed)

- `MetricsCalculator`
  - Inputs: Frames from a `SwingSegment` with integrated pose and object detection data
  - Outputs: Enhanced kinematic metrics, swing paths, contact point analysis, and object tracking metrics
  - Guarantees: Smoothed values within configured ranges; deterministic results for identical inputs; integrates ball and racket tracking data

- `VideoProcessor`
  - Inputs: Source descriptor (live or file)
  - Outputs: Collection of `AnalysisResult`s for detected swings with object detection integration and propagated `keyFrameTimes`
  - Guarantees: Orchestrates full pipeline off the main thread; batches work for files; incremental accumulation during live capture; exposes progress via `ProcessingState` (pose extraction → object detection → swing detection → metrics → validation)

- `ProcessingManager` (Singleton)
  - Inputs: Session and video URL pairs for processing
  - Outputs: Background-processed sessions with updated ProcessingStatus
  - Guarantees: Maximum 2 concurrent processing operations; automatic queue management for pending tasks; state synchronization with SessionStore; retry logic with configurable max attempts (default: 3); cleanup of completed processors

- `NavigationState`
  - Inputs: Navigation destinations and sheet presentations
  - Outputs: Reactive navigation path updates
  - Guarantees: Type-safe navigation with enum destinations; centralized sheet management; maintains navigation history for back navigation

- Storage layer
  - Inputs: `AnalysisResult`s (including optional `keyFrameTimes`) and associated media URLs
  - Outputs: Persisted sessions and shots retrievable for `MainView` cards; `Shot` persists `keyFrameTimes` when available
  - Guarantees (MVP): `SessionStore` saves session metadata (id/date/video file name/shot count). `AnalysisStore` saves per‑video analysis display data (`duration`, `[Shot]`). `SessionSummary` can be derived for UI badges.
  - Future Guarantees: Migrate to Core Data to persist richer `AnalysisResult` fields, full metrics, and relationships between sessions and shots.

## Data Flow Scenarios

- Live recording (Non-blocking MVP flow)
  1. From `MainView` → Floating action → Record Now → `CameraView`.
  2. User records with real-time overlays (`SkeletonOverlay`, `BallOverlay`, `RacketOverlay`); video saved to Documents directory.
  3. Session created immediately with `pending` status and appears in MainView.
  4. App returns to MainView; new session card shows with `VideoProcessingOverlay`.
  5. `ProcessingManager` starts background processing:
     - `PoseProcessor` extracts poses (status: extractingPoses with progress)
     - `TennisObjectDetector` detects balls/rackets (status: detectingObjects with progress)
     - `SwingDetector` finds swing boundaries (status: detectingSwings)
     - `MetricsCalculator` computes enhanced metrics (status: calculatingMetrics)
     - `GeminiValidator` validates swings (status: validatingSwings x/y)
  6. `VideoSessionCard` shows inline progress updates in real-time.
  7. On completion (status: complete), tapping card navigates to `AnalysisView` with simple swing metrics display.
  8. On error (status: failed), error overlay shows with retry option.

- Video upload (Non-blocking MVP flow)
  1. From `MainView` → Floating action → Upload Video → Photos picker.
  2. User selects file; video copied to Documents directory.
  3. Session created immediately with `pending` status and appears in MainView.
  4. App returns to MainView; new session card shows processing status.
  5. `ProcessingManager` queues and processes video in background:
     - Respects 2-concurrent limit; queues if at capacity
     - Updates session ProcessingStatus throughout enhanced pipeline
     - Maps VideoProcessor states (pose → object detection → swing detection → metrics → validation) to UI-friendly status messages
  6. `VideoSessionCard` displays real-time status updates inline with processing progress.
  7. On completion, `ProcessingManager` saves results with metrics data via `AnalysisStore`.
  8. Tapping completed session (status: complete) navigates to `AnalysisView` with simple swing metrics display.
  9. Processing continues even if user navigates away (true background operation).
  10. If app is terminated, sessions resume from last known state on restart.

## Performance & Resource Management

- Throughput: Optionally process every third frame in live mode to target ~10 fps effective pose estimation and object detection.
- Memory: Maintain small rolling buffers for pose frames and object detections (~three seconds each); YOLO11 model bundle (~50MB) loaded once and cached.
- Background work: Run pose detection, object detection, and heavy analysis off the main thread via ProcessingManager.
- Concurrency: Limit to 2 simultaneous video processing operations to prevent resource exhaustion; YOLO11 operations use optimized CoreML inference.
- Queue management: Pending videos automatically process when capacity available; object detection integrated into existing pipeline.
- Batching: Handle uploaded videos in manageable chunks to keep memory stable; coordinate pose and object detection processing.
- Storage hygiene: Support video retention policy (e.g., delete items older than 30 days) and expose total storage used including YOLO11 model storage (~50MB).
- Thumbnail generation: Async generation with file path persistence for quick loading.
- Model optimization: YOLO11 CoreML model optimized for iOS with FP16 precision for balanced performance and accuracy.

## MVP Simplifications

The current implementation includes several simplifications for the MVP release:

- **No Partial View**: Users cannot view partial analysis results during processing. The AnalysisView is only accessible when processingStatus is complete.
- **Simplified Navigation**: Removed complexity by eliminating partial analysis states.
- **Consolidated Components**: Error overlays merged into ProcessingView for better organization.
- **Clearer Naming**: Components renamed for explicit purpose (VideoProcessingOverlay, ProcessingErrorOverlay).
- **Background Processing**: True non-blocking operation allows users to continue using the app while videos process.
- **Visual Feedback**: Inline status updates on video cards provide clear progress indication without modal interruption.
- **Simple Metrics Display**: Replaced AI analysis features with straightforward display of SegmentMetrics data (peak speed, shoulder turn, contact height, follow through, tracking quality). No complex AI insights or on-demand analysis.

These simplifications can be revisited post-MVP based on user feedback and usage patterns.

## Platform & Privacy

- Device: Vision body pose and YOLO11 CoreML require a real device; target iOS 14.0+ (VNDetectHumanBodyPoseRequest, CoreML). iPhone 12 or newer recommended for optimal performance with dual AI processing.
- Model Requirements: YOLO11 CoreML model requires ~50MB storage and A12 Bionic chip or newer for optimal inference performance.
- Privacy: Obtain user consent before sending frames for cloud analysis; downsample images (e.g., 480p) prior to upload; exclude PII; provide option to disable cloud processing; object detection runs entirely on-device via CoreML.

## Accessibility & UX Principles

- Target sizes: 44‑point minimum for primary taps; 56‑point timeline band; 64‑point floating action button.
- Redundant cues: Use text + shape, not color alone, for markers and chips.
- VoiceOver: `TimelineStripEnhanced` exposes adjustable previous/next, descriptive labels/values; coach card carousel provides navigation feedback; object detection overlays include accessibility labels for ball and racket positions. Floating action button labeled "Record or upload swing".
- Haptics: Provide selection feedback on timeline changes, coach card navigation, and successful object detection events.

Design system adaptations:
- Respect Reduce Motion and Reduce Transparency. `Theme` exposes these preferences; components should avoid continuous animations and reduce/transparencies when enabled.
- Use `GlassContainer` for surfaces; keep shadows light-mode only and ensure borders for contrast in both color schemes. For detail screens like `CoachDetailView`, avoid redundant backgrounds—prefer one primary card surface per story.
- Prefer design tokens: colors from `TennisColors`, spacing from `Spacing`, and monospaced metrics via `TennisTypography.MetricStyle`.

## Error Handling & Reliability

- Detection timeouts and threshold validation to avoid false positives.
- Clear separation of recoverable (e.g., transient I/O) vs non‑recoverable errors.
- Retry mechanism: Up to 3 attempts for failed processing with exponential backoff.
- Error states: Visual feedback via ProcessingErrorOverlay with retry option.
- Session persistence: ProcessingStatus and error state survive app restarts.
- Persistence safeguards and basic media integrity checks.
- Minimal but useful logging around pipeline stages for diagnostics.
- Graceful degradation: Sessions remain viewable even if processing fails.

## Testing Strategy

- Unit tests: `SwingDetector` with synthetic or recorded pose sequences; metrics with known inputs.
- Integration: End‑to‑end runs with representative tennis videos.
- Performance: Multi‑minute clips to validate steady throughput.
- Memory: Extended live recording sessions to observe stability.


