# Tennis App - Core Architecture & Implementation Guide

## Purpose & Audience

This guide is for architects and senior developers. It explains design intent, module responsibilities, and plain‑language contracts. It avoids code and focuses on how parts fit together and what they guarantee.

## System Overview

The app processes tennis swings from video (live or recorded) using Apple's Vision framework to detect body pose, analyzes motion patterns, and provides coaching feedback.

## Architecture at a Glance

Input → Processing Pipeline → Storage → UI

- Input: Camera capture and file import (triggered from MainView floating action button)
- Processing: Pose extraction → Swing detection → Metrics and insights → Orchestration
- Storage: Local media management and structured persistence
- UI: Single MainView dashboard with session cards, Analysis detail, and Camera capture

## File Structure

```
swingmaster/
├── Assets.xcassets/
├── DesignSystem/
│   ├── Colors.swift              # Color tokens & semantic colors (dark-mode aware)
│   ├── Typography.swift          # Type scale helpers & MetricStyle
│   ├── Spacing.swift             # 4pt grid spacing tokens
│   ├── Theme.swift               # Environment object (reduce motion/transparency)
│   └── Components/
│       ├── GlassContainer.swift  # Reusable glass-morphism container
│       └── TennisAvatar.swift    # Solid color avatar with initial
├── Components/
│   ├── TimelineStrip.swift
│   ├── ShotChipsRow.swift
│   ├── VideoPlayerView.swift
│   ├── SkeletonOverlay.swift
│   ├── VideoSessionCard.swift      # NEW: Video-primary session card
│   ├── CoachCard.swift             # NEW: Minimal AI insight card
│   ├── FloatingActionButton.swift  # NEW: Record/Upload trigger
│   └── RecordOptionsModal.swift    # NEW: Action chooser (Record Now / Upload)
├── Managers/
│   ├── CameraManager.swift
│   ├── SessionStore.swift
│   └── AnalysisStore.swift   # MVP persistence of analysis-by-video
├── Mock/
│   └── MockSwingDetector.swift
├── Models/
│   ├── Shot.swift
│   └── SessionSummary.swift        # NEW: Aggregated session data (avg score, breakdown)
├── Utils/
│   └── VideoStorage.swift
├── Views/
│   ├── MainView.swift              # NEW: Single scrollable dashboard (root)
│   ├── CameraView.swift
│   └── AnalysisView.swift
├── ContentView.swift
└── swingmasterApp.swift
```

## Module Responsibilities (by directory)

- DesignSystem
  - `Colors.swift`: Provides base palette (tennis greens/yellow/clay) and semantic colors; dynamic color variants for dark mode; hex initializers for `Color`/`UIColor`.
  - `Typography.swift`: Convenience functions for common text styles (`largeTitle`, `headline`, `metric`) and `MetricStyle` ViewModifier; encourages monospaced metrics to avoid layout shift.
  - `Spacing.swift`: 4pt grid design tokens (`micro` → `xxlarge`) and convenience constants (`cardPadding`, `screenMargin`, `sectionGap`).
  - `Theme.swift`: Environment-backed object exposing `colorScheme`, `useReducedTransparency`, and `useReduceMotion` for adaptive UI decisions.
  - `Components/GlassContainer.swift`: Standardized glass-morphism container with style presets (subtle/medium/heavy), bordered edges, and light-mode-only shadow.
  - `Components/TennisAvatar.swift`: Simple solid color avatar (no gradients) rendering the user's initial with tennis theme color.

- Core
  - `PoseProcessor.swift`: Extracts human pose from frames or video using Vision; normalizes coordinates; provides timestamped pose frames to downstream modules.
  - `SwingDetector.swift`: Finds peaks in motion and extracts short candidate segments; emits `PotentialSwing`s rather than final segments.
  - `MetricsCalculator.swift`: Derives kinematic measures (e.g., wrist speed, contact point, body angles) and simplified swing paths; applies smoothing.
  - `GeminiValidator.swift`: Validates `PotentialSwing`s with 30‑frame context, refines exact start/end, classifies swing type, and produces analysis insights.
  - `VideoProcessor.swift`: Orchestrates end‑to‑end processing for live and file sources; sequences pose extraction, detection, and per‑swing analysis to produce results.

- Models
  - `PoseFrame.swift`: One frame of normalized pose data with joint confidences; the common currency for detection and metrics.
  - `SwingSegment.swift`: A detected swing with start/end times, type, constituent frames, and optional video linkage; the unit of analysis.
  - `AnalysisResult.swift`: The finalized outcome for a swing, including metrics, insights, and a score; suitable for storage and display.

- Components (UI)
  - `TimelineStrip.swift`: 56‑point overlay timeline with shot markers; supports snap‑to‑nearest selection, haptics, and VoiceOver adjustability.
  - `ShotChipsRow.swift`: 44‑point scrollable chips for primary navigation with previous/next controls and descriptive accessibility labels.
  - `SkeletonOverlay.swift`: Draws real‑time body skeleton from pose frames; converts Vision coordinates to view space; animates lines between joints with confidence‑based coloring; handles device orientation.

- Storage
  - `AnalysisStore.swift` (MVP): Persists per‑video analysis results for `AnalysisView` via `UserDefaults`, keyed by video file name. Stores `duration` and `[MockShot]` only. Intended as a temporary solution before Core Data.
  - `CoreDataManager.swift` (Future): Persistence boundary; initializes Core Data and saves/fetches sessions and shots.
  - `VideoStorage.swift`: Manages app‑owned video files (move from temp, delete, measure total size) and supports retention policies.
  - `TennisApp.xcdatamodeld` (Future): Core Data schema describing `Session` and `Shot` entities and their relationship.

- Views
  - `MainView.swift`: Single scrollable dashboard using design-system tokens. Profile header uses `TennisAvatar`; empty state uses `GlassContainer(.subtle)`; shows `CoachCard` and `VideoSessionCard` list. Floating action button overlays and opens `RecordOptionsModal` for Record/Upload.
  - `CameraView.swift`: Recording UI and preview; integrates live processing during capture and exposes start/end controls. Simplified: no History/Upload buttons.
  - `AnalysisView.swift`: Presents metrics, insights, score, and navigation controls (timeline and chips); allows scrubbing to key moments.

- Utils
  - `FrameBuffer.swift`: Fixed‑size circular buffer for recent pose frames, optimized for constant‑time append and bounded memory.
  - `VideoStorage.generateThumbnail(for:at:)` supports timestamped thumbnails for `VideoSessionCard`.
  - Smoothing lives within `MetricsCalculator` in the MVP; a separate `SignalProcessor.swift` can be introduced later if needed.

## Interfaces & Contracts (plain language)

- `PoseProcessor`
  - Inputs: Camera frames or video files
  - Outputs: Ordered `PoseFrame`s with normalized coordinates and confidence values
  - Guarantees: Background execution for heavy work; consistent coordinate system; optional downsampling

- `SwingDetector`
  - Inputs: Time‑ordered `PoseFrame`s
  - Outputs: `PotentialSwing` candidates around velocity peaks (not final boundaries)
  - Guarantees: Bounded internal buffer; simple threshold‑based state machine; emits candidates with sufficient context for validation

- `GeminiValidator`
  - Inputs: `PotentialSwing`s (≈30 frames) and optional precomputed metrics
  - Outputs: Validated swings with refined start/end frames, swing type, confidence, and analysis insights
  - Guarantees: Uses 30‑frame context; network‑robust with retries and basic rate limiting; returns deterministic JSON schema

- `MetricsCalculator`
  - Inputs: Frames from a `SwingSegment`
  - Outputs: Kinematic metrics, simplified paths, and helper detections (e.g., contact point)
  - Guarantees: Smoothed values within configured ranges; deterministic results for identical inputs

- `VideoProcessor`
  - Inputs: Source descriptor (live or file)
  - Outputs: Collection of `AnalysisResult`s for detected swings
  - Guarantees: Orchestrates pipeline off the main thread; batches work for files; incremental accumulation during live capture; exposes progress via `ProcessingState` (pose extraction → metrics → detection → validation → analysis)

- Storage layer
  - Inputs: `AnalysisResult`s and associated media URLs
  - Outputs: Persisted sessions and shots retrievable for `MainView` cards
  - Guarantees (MVP): `SessionStore` saves session metadata (id/date/video file name/shot count). `AnalysisStore` saves per‑video analysis display data (`duration`, `[MockShot]`). `SessionSummary` can be derived for UI badges.
  - Future Guarantees: Migrate to Core Data to persist richer `AnalysisResult` fields, full metrics, and relationships between sessions and shots.

## Data Flow Scenarios

- Live recording
  1. From `MainView` → Floating action → Record Now → `CameraView`.
  2. User records; frames are produced by the camera.
  3. `PoseProcessor` converts frames to `PoseFrame`s on a background queue.
  4. `SwingDetector` ingests frames and monitors thresholds to find swing boundaries.
  5. When capture ends or a swing completes, a `SwingSegment` is finalized.
  6. `MetricsCalculator` computes metrics and insights for the segment.
  7. On completion, app navigates to `ProcessingView` (or directly to `AnalysisView` if already available) and persists results.

- Video upload
  1. From `MainView` → Floating action → Upload Video → Photos picker.
  2. User selects a file; frames are sampled at a steady rate.
  3. `PoseProcessor` batch‑extracts pose frames.
  4. `SwingDetector` processes frames to detect swings.
  5. Each detected swing is analyzed. On completion, `ContentView` maps results to `MockShot` and uses `AnalysisStore.save(videoURL:duration:shots:)`. `SessionStore` saves session metadata.
  6. Tapping a session card in `MainView` attempts `AnalysisStore.load(videoURL:)`. If found, the app navigates directly to `AnalysisView`; otherwise it goes to `ProcessingView`.

## Performance & Resource Management

- Throughput: Optionally process every third frame in live mode to target ~10 fps effective pose estimation.
- Memory: Maintain a small rolling buffer (~three seconds of frames) for detection.
- Background work: Run pose detection and heavy analysis off the main thread.
- Batching: Handle uploaded videos in manageable chunks to keep memory stable.
- Storage hygiene: Support a video retention policy (e.g., delete items older than 30 days) and expose total storage used.

## Platform & Privacy

- Device: Vision body pose requires a real device; target iOS 14.0+ (VNDetectHumanBodyPoseRequest). iPhone 12 or newer recommended for performance.
- Privacy: Obtain user consent before sending frames for cloud analysis; downsample images (e.g., 480p) prior to upload; exclude PII; provide an option to disable cloud processing.

## Accessibility & UX Principles

- Target sizes: 44‑point minimum for primary taps; 56‑point timeline band; 64‑point floating action button.
- Redundant cues: Use text + shape, not color alone, for markers and chips.
- VoiceOver: `TimelineStrip` exposes adjustable previous/next, descriptive labels/values; chips provide full labels (e.g., type + score). Floating action button labeled "Record or upload swing".
- Haptics: Provide selection feedback on timeline and chip changes.

Design system adaptations:
- Respect Reduce Motion and Reduce Transparency. `Theme` exposes these preferences; components should avoid continuous animations and reduce/transparencies when enabled.
- Use `GlassContainer` for surfaces; keep shadows light-mode only and ensure borders for contrast in both color schemes.
- Prefer design tokens: colors from `TennisColors`, spacing from `Spacing`, and monospaced metrics via `TennisTypography.MetricStyle`.

## Error Handling & Reliability

- Detection timeouts and threshold validation to avoid false positives.
- Clear separation of recoverable (e.g., transient I/O) vs non‑recoverable errors.
- Persistence safeguards and basic media integrity checks.
- Minimal but useful logging around pipeline stages for diagnostics.

## Testing Strategy

- Unit tests: `SwingDetector` with synthetic or recorded pose sequences; metrics with known inputs.
- Integration: End‑to‑end runs with representative tennis videos.
- Performance: Multi‑minute clips to validate steady throughput.
- Memory: Extended live recording sessions to observe stability.


