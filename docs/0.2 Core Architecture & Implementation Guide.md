# Tennis App - Core Architecture & Implementation Guide

## Purpose & Audience

This guide is for architects and senior developers. It explains design intent, module responsibilities, and plain‑language contracts. It avoids code and focuses on how parts fit together and what they guarantee.

## System Overview

The app processes tennis swings from video (live or recorded) using Apple's Vision framework to detect body pose, analyzes motion patterns, and provides coaching feedback.

## Architecture at a Glance

Input → Processing Pipeline → Storage → UI

- Input: Camera capture and file import (triggered from MainView floating action button)
- Processing: Pose extraction → Swing detection → Metrics and insights → Orchestration
- Storage: Local media management and structured persistence
- UI: Single MainView dashboard with session cards, Analysis detail, and Camera capture

## File Structure

```
swingmaster/
├── Assets.xcassets/
├── DesignSystem/
│   ├── Colors.swift              # Color tokens & semantic colors (dark-mode aware)
│   ├── Typography.swift          # Type scale helpers & MetricStyle
│   ├── Spacing.swift             # 4pt grid spacing tokens
│   ├── Theme.swift               # Environment object (reduce motion/transparency)
│   └── Components/
│       ├── GlassContainer.swift  # Reusable glass-morphism container
│       └── TennisAvatar.swift    # Solid color avatar with initial
├── Components/
│   ├── TimelineStrip.swift
│   ├── ShotChipsRow.swift
│   ├── VideoPlayerView.swift
│   ├── SkeletonOverlay.swift
│   ├── VideoSessionCard.swift         # Video-primary session card with inline processing
│   ├── VideoProcessingOverlay.swift   # Inline processing status overlay
│   ├── CoachCard.swift                # Minimal AI insight card
│   ├── FloatingActionButton.swift     # Record/Upload trigger
│   └── RecordOptionsModal.swift       # Action chooser (Record Now / Upload)
├── Managers/
│   ├── CameraManager.swift
│   ├── SessionStore.swift          # Enhanced with ProcessingStatus tracking
│   ├── ProcessingManager.swift     # Singleton for background video processing
│   └── AnalysisStore.swift         # MVP persistence of analysis-by-video
├── Navigation/
│   └── NavigationState.swift      # Centralized navigation state management
├── Core/
│   ├── PoseProcessor.swift
│   ├── SwingDetector.swift
│   ├── MetricsCalculator.swift
│   ├── GeminiValidator.swift
│   └── VideoProcessor.swift
├── Mock/
│   └── MockSwingDetector.swift
├── Models/
│   ├── Shot.swift
│   └── SessionSummary.swift        # NEW: Aggregated session data (avg score, breakdown)
├── Utils/
│   └── VideoStorage.swift
├── Views/
│   ├── MainView.swift              # Single scrollable dashboard (root)
│   ├── CameraView.swift
│   ├── ProcessingView.swift        # Includes ProcessingErrorOverlay for error states
│   ├── AnalysisView.swift
│   └── CoachDetailView.swift       # Unified card: tag + title + markdown
├── ContentView.swift
└── swingmasterApp.swift
```

## Module Responsibilities (by directory)

- DesignSystem
  - `Colors.swift`: Provides base palette (tennis greens/yellow/clay) and semantic colors; dynamic color variants for dark mode; hex initializers for `Color`/`UIColor`.
  - `Typography.swift`: Convenience functions for common text styles (`largeTitle`, `headline`, `metric`) and `MetricStyle` ViewModifier; encourages monospaced metrics to avoid layout shift.
  - `Spacing.swift`: 4pt grid design tokens (`micro` → `xxlarge`) and convenience constants (`cardPadding`, `screenMargin`, `sectionGap`).
  - `Theme.swift`: Environment-backed object exposing `colorScheme`, `useReducedTransparency`, and `useReduceMotion` for adaptive UI decisions.
  - `Components/GlassContainer.swift`: Standardized glass-morphism container with style presets (subtle/medium/heavy), bordered edges, and light-mode-only shadow.
  - `Components/TennisAvatar.swift`: Simple solid color avatar (no gradients) rendering the user's initial with tennis theme color.

- Core
  - `PoseProcessor.swift`: Extracts human pose from frames or video using Vision; normalizes coordinates; provides timestamped pose frames to downstream modules.
  - `SwingDetector.swift`: Finds peaks in motion and extracts short candidate segments; emits `PotentialSwing`s rather than final segments.
  - `MetricsCalculator.swift`: Derives kinematic measures (e.g., wrist speed, contact point, body angles) and simplified swing paths; applies smoothing.
  - `GeminiValidator.swift`: Validates `PotentialSwing`s with 30‑frame context, refines exact start/end, classifies swing type, and produces analysis insights.
  - `VideoProcessor.swift`: Orchestrates end‑to‑end processing for live and file sources; sequences pose extraction, detection, and per‑swing analysis to produce results.

- Models
  - `PoseFrame.swift`: One frame of normalized pose data with joint confidences; the common currency for detection and metrics.
  - `SwingSegment.swift`: A detected swing with start/end times, type, constituent frames, and optional video linkage; the unit of analysis.
  - `AnalysisResult.swift`: The finalized outcome for a swing, including metrics, insights, and a score; suitable for storage and display.

- Components (UI)
  - `TimelineStrip.swift`: 56‑point overlay timeline with shot markers; supports snap‑to‑nearest selection, haptics, and VoiceOver adjustability.
  - `ShotChipsRow.swift`: 44‑point scrollable chips for primary navigation with previous/next controls and descriptive accessibility labels.
  - `SkeletonOverlay.swift`: Draws real‑time body skeleton from pose frames; converts Vision coordinates to view space; animates lines between joints with confidence‑based coloring; handles device orientation.
  - `VideoProcessingOverlay.swift`: Non-blocking inline overlay showing processing status on video cards; displays progress for pose extraction, swing validation, and AI analysis stages; uses ultra-thin material background with status text.
  - `VideoSessionCard.swift`: Enhanced to show inline processing status using VideoProcessingOverlay; displays error states with retry functionality via ProcessingErrorOverlay; maintains responsiveness during background processing.

- Managers & Storage
  - `SessionStore.swift`: Enhanced with ProcessingStatus enum tracking (pending, extractingPoses, calculatingMetrics, detectingSwings, validatingSwings, analyzingSwings, complete, failed); supports updateSession for reactive state changes; manages session metadata with retry counts and error tracking.
  - `ProcessingManager.swift`: Singleton managing concurrent video processing tasks; limits to 2 concurrent operations; maintains queue for pending tasks; maps VideoProcessor states to Session.ProcessingStatus; handles retry logic with configurable max attempts (default: 3).
  - `NavigationState.swift`: Centralized navigation state using NavigationPath; manages sheet presentations; provides push/pop methods for programmatic navigation; single source of truth for app navigation flow.
  - `AnalysisStore.swift` (MVP): Persists per‑video analysis results for `AnalysisView` via `UserDefaults`, keyed by video file name. Stores `duration` and `[MockShot]` only. Intended as a temporary solution before Core Data.
  - `CoreDataManager.swift` (Future): Persistence boundary; initializes Core Data and saves/fetches sessions and shots.
  - `VideoStorage.swift`: Manages app‑owned video files (move from temp, delete, measure total size); enhanced with async thumbnail generation that returns file paths; supports retention policies.
  - `TennisApp.xcdatamodeld` (Future): Core Data schema describing `Session` and `Shot` entities and their relationship.

- Views
  - `MainView.swift`: Single scrollable dashboard using design-system tokens. Profile header uses `TennisAvatar`; empty state uses `GlassContainer(.subtle)`; shows `CoachCard` and `VideoSessionCard` list with inline processing status. Floating action button overlays and opens `RecordOptionsModal` for Record/Upload.
  - `CameraView.swift`: Recording UI and preview; returns video URL to ContentView for immediate session creation and background processing. Simplified: no History/Upload buttons.
  - `ProcessingView.swift`: Legacy blocking processing view (being phased out); includes `ProcessingErrorOverlay` for centralized error state handling with retry functionality.
  - `AnalysisView.swift`: Presents metrics, insights, score, and navigation controls (timeline and chips); only accessible when session.processingStatus is complete (MVP simplification - no partial view).
  - `CoachDetailView.swift`: Presents a unified coaching card using `GlassContainer(style: .medium, cornerRadius: 16)` that combines the tag badge, 28pt title, and full markdown content with consistent `Spacing.cardPadding`. Screen background is clear so the card is the sole surface; video CTA sits below the card.

- Utils
  - `FrameBuffer.swift`: Fixed‑size circular buffer for recent pose frames, optimized for constant‑time append and bounded memory.
  - `VideoStorage.generateThumbnail(for:at:)` supports timestamped thumbnails for `VideoSessionCard`.
  - Smoothing lives within `MetricsCalculator` in the MVP; a separate `SignalProcessor.swift` can be introduced later if needed.

## Interfaces & Contracts (plain language)

- `PoseProcessor`
  - Inputs: Camera frames or video files
  - Outputs: Ordered `PoseFrame`s with normalized coordinates and confidence values
  - Guarantees: Background execution for heavy work; consistent coordinate system; optional downsampling

- `SwingDetector`
  - Inputs: Time‑ordered `PoseFrame`s
  - Outputs: `PotentialSwing` candidates around velocity peaks (not final boundaries)
  - Guarantees: Bounded internal buffer; simple threshold‑based state machine; emits candidates with sufficient context for validation

- `GeminiValidator`
  - Inputs: `PotentialSwing`s (≈30 frames) and optional precomputed metrics
  - Outputs: Validated swings with refined start/end frames, swing type, confidence, and analysis insights
  - Guarantees: Uses 30‑frame context; network‑robust with retries and basic rate limiting; returns deterministic JSON schema

- `MetricsCalculator`
  - Inputs: Frames from a `SwingSegment`
  - Outputs: Kinematic metrics, simplified paths, and helper detections (e.g., contact point)
  - Guarantees: Smoothed values within configured ranges; deterministic results for identical inputs

- `VideoProcessor`
  - Inputs: Source descriptor (live or file)
  - Outputs: Collection of `AnalysisResult`s for detected swings
  - Guarantees: Orchestrates pipeline off the main thread; batches work for files; incremental accumulation during live capture; exposes progress via `ProcessingState` (pose extraction → metrics → detection → validation → analysis)

- `ProcessingManager` (Singleton)
  - Inputs: Session and video URL pairs for processing
  - Outputs: Background-processed sessions with updated ProcessingStatus
  - Guarantees: Maximum 2 concurrent processing operations; automatic queue management for pending tasks; state synchronization with SessionStore; retry logic with configurable max attempts (default: 3); cleanup of completed processors

- `NavigationState`
  - Inputs: Navigation destinations and sheet presentations
  - Outputs: Reactive navigation path updates
  - Guarantees: Type-safe navigation with enum destinations; centralized sheet management; maintains navigation history for back navigation

- Storage layer
  - Inputs: `AnalysisResult`s and associated media URLs
  - Outputs: Persisted sessions and shots retrievable for `MainView` cards
  - Guarantees (MVP): `SessionStore` saves session metadata (id/date/video file name/shot count). `AnalysisStore` saves per‑video analysis display data (`duration`, `[MockShot]`). `SessionSummary` can be derived for UI badges.
  - Future Guarantees: Migrate to Core Data to persist richer `AnalysisResult` fields, full metrics, and relationships between sessions and shots.

## Data Flow Scenarios

- Live recording (Non-blocking MVP flow)
  1. From `MainView` → Floating action → Record Now → `CameraView`.
  2. User records; video saved to Documents directory.
  3. Session created immediately with `pending` status and appears in MainView.
  4. App returns to MainView; new session card shows with `VideoProcessingOverlay`.
  5. `ProcessingManager` starts background processing:
     - `PoseProcessor` extracts poses (status: extractingPoses with progress)
     - `SwingDetector` finds swing boundaries (status: detectingSwings)
     - `MetricsCalculator` computes metrics (status: calculatingMetrics)
     - `GeminiValidator` validates swings (status: validatingSwings x/y)
     - AI analysis performed (status: analyzingSwings x/y)
  6. `VideoSessionCard` shows inline progress updates in real-time.
  7. On completion (status: complete), tapping card navigates to `AnalysisView`.
  8. On error (status: failed), `ProcessingErrorOverlay` shows with retry option.

- Video upload (Non-blocking MVP flow)
  1. From `MainView` → Floating action → Upload Video → Photos picker.
  2. User selects file; video copied to Documents directory.
  3. Session created immediately with `pending` status and appears in MainView.
  4. App returns to MainView; new session card shows processing status.
  5. `ProcessingManager` queues and processes video in background:
     - Respects 2-concurrent limit; queues if at capacity
     - Updates session ProcessingStatus throughout pipeline
     - Maps VideoProcessor states to UI-friendly status messages
  6. `VideoSessionCard` displays real-time status updates inline.
  7. On completion, `ProcessingManager` saves results via `AnalysisStore`.
  8. Tapping completed session (status: complete) navigates to `AnalysisView`.
  9. Processing continues even if user navigates away (true background operation).
  10. If app is terminated, sessions resume from last known state on restart.

## Performance & Resource Management

- Throughput: Optionally process every third frame in live mode to target ~10 fps effective pose estimation.
- Memory: Maintain a small rolling buffer (~three seconds of frames) for detection.
- Background work: Run pose detection and heavy analysis off the main thread via ProcessingManager.
- Concurrency: Limit to 2 simultaneous video processing operations to prevent resource exhaustion.
- Queue management: Pending videos automatically process when capacity available.
- Batching: Handle uploaded videos in manageable chunks to keep memory stable.
- Storage hygiene: Support a video retention policy (e.g., delete items older than 30 days) and expose total storage used.
- Thumbnail generation: Async generation with file path persistence for quick loading.

## MVP Simplifications

The current implementation includes several simplifications for the MVP release:

- **No Partial View**: Users cannot view partial analysis results during processing. The AnalysisView is only accessible when processingStatus is complete.
- **Simplified Navigation**: Removed complexity by eliminating partial analysis states.
- **Consolidated Components**: Error overlays merged into ProcessingView for better organization.
- **Clearer Naming**: Components renamed for explicit purpose (VideoProcessingOverlay, ProcessingErrorOverlay).
- **Background Processing**: True non-blocking operation allows users to continue using the app while videos process.
- **Visual Feedback**: Inline status updates on video cards provide clear progress indication without modal interruption.

These simplifications can be revisited post-MVP based on user feedback and usage patterns.

## Platform & Privacy

- Device: Vision body pose requires a real device; target iOS 14.0+ (VNDetectHumanBodyPoseRequest). iPhone 12 or newer recommended for performance.
- Privacy: Obtain user consent before sending frames for cloud analysis; downsample images (e.g., 480p) prior to upload; exclude PII; provide an option to disable cloud processing.

## Accessibility & UX Principles

- Target sizes: 44‑point minimum for primary taps; 56‑point timeline band; 64‑point floating action button.
- Redundant cues: Use text + shape, not color alone, for markers and chips.
- VoiceOver: `TimelineStrip` exposes adjustable previous/next, descriptive labels/values; chips provide full labels (e.g., type + score). Floating action button labeled "Record or upload swing".
- Haptics: Provide selection feedback on timeline and chip changes.

Design system adaptations:
- Respect Reduce Motion and Reduce Transparency. `Theme` exposes these preferences; components should avoid continuous animations and reduce/transparencies when enabled.
- Use `GlassContainer` for surfaces; keep shadows light-mode only and ensure borders for contrast in both color schemes. For detail screens like `CoachDetailView`, avoid redundant backgrounds—prefer one primary card surface per story.
- Prefer design tokens: colors from `TennisColors`, spacing from `Spacing`, and monospaced metrics via `TennisTypography.MetricStyle`.

## Error Handling & Reliability

- Detection timeouts and threshold validation to avoid false positives.
- Clear separation of recoverable (e.g., transient I/O) vs non‑recoverable errors.
- Retry mechanism: Up to 3 attempts for failed processing with exponential backoff.
- Error states: Visual feedback via ProcessingErrorOverlay with retry option.
- Session persistence: ProcessingStatus and error state survive app restarts.
- Persistence safeguards and basic media integrity checks.
- Minimal but useful logging around pipeline stages for diagnostics.
- Graceful degradation: Sessions remain viewable even if processing fails.

## Testing Strategy

- Unit tests: `SwingDetector` with synthetic or recorded pose sequences; metrics with known inputs.
- Integration: End‑to‑end runs with representative tennis videos.
- Performance: Multi‑minute clips to validate steady throughput.
- Memory: Extended live recording sessions to observe stability.


