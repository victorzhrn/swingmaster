# Tennis App - Core Architecture & Implementation Guide

## Purpose & Audience

This guide is for architects and senior developers. It explains design intent, module responsibilities, and plain‑language contracts. It avoids code and focuses on how parts fit together and what they guarantee.

## System Overview

The app processes tennis swings from video (live or recorded) using Apple's Vision framework to detect body pose, analyzes motion patterns, and provides coaching feedback.

## Architecture at a Glance

Input → Processing Pipeline → Storage → UI

- Input: Camera capture and file import
- Processing: Pose extraction → Swing detection → Metrics and insights → Orchestration
- Storage: Local media management and structured persistence
- UI: Capture, analysis, and history surfaces

## File Structure

```
swingmaster/
├── Assets.xcassets/
├── Components/
│   ├── TimelineStrip.swift
│   ├── ShotChipsRow.swift
│   ├── VideoPlayerView.swift
│   └── SkeletonOverlay.swift
├── Managers/
│   ├── CameraManager.swift
│   └── SessionStore.swift
├── Mock/
│   └── MockSwingDetector.swift
├── Models/
│   └── Shot.swift
├── Utils/
│   └── VideoStorage.swift
├── Views/
│   ├── CameraView.swift
│   ├── AnalysisView.swift
│   └── HistoryView.swift
├── ContentView.swift
└── swingmasterApp.swift
```

## Module Responsibilities (by directory)

- Core
  - `PoseProcessor.swift`: Extracts human pose from frames or video using Vision; normalizes coordinates; provides timestamped pose frames to downstream modules.
  - `SwingDetector.swift`: Finds peaks in motion and extracts short candidate segments; emits `PotentialSwing`s rather than final segments.
  - `MetricsCalculator.swift`: Derives kinematic measures (e.g., wrist speed, contact point, body angles) and simplified swing paths; applies smoothing.
  - `GeminiValidator.swift`: Validates `PotentialSwing`s with 30‑frame context, refines exact start/end, classifies swing type, and produces analysis insights.
  - `VideoProcessor.swift`: Orchestrates end‑to‑end processing for live and file sources; sequences pose extraction, detection, and per‑swing analysis to produce results.

- Models
  - `PoseFrame.swift`: One frame of normalized pose data with joint confidences; the common currency for detection and metrics.
  - `SwingSegment.swift`: A detected swing with start/end times, type, constituent frames, and optional video linkage; the unit of analysis.
  - `AnalysisResult.swift`: The finalized outcome for a swing, including metrics, insights, and a score; suitable for storage and display.

- Components (UI)
  - `TimelineStrip.swift`: 56‑point overlay timeline with shot markers; supports snap‑to‑nearest selection, haptics, and VoiceOver adjustability.
  - `ShotChipsRow.swift`: 44‑point scrollable chips for primary navigation with previous/next controls and descriptive accessibility labels.
  - `SkeletonOverlay.swift`: Draws real‑time body skeleton from pose frames; converts Vision coordinates to view space; animates lines between joints with confidence‑based coloring; handles device orientation.

- Storage
  - `CoreDataManager.swift`: Persistence boundary; initializes Core Data and saves/fetches sessions and shots.
  - `VideoStorage.swift`: Manages app‑owned video files (move from temp, delete, measure total size) and supports retention policies.
  - `TennisApp.xcdatamodeld`: Core Data schema describing `Session` and `Shot` entities and their relationship.

- Views
  - `CameraView.swift`: Recording UI and preview; integrates live processing during capture and exposes start/end controls.
  - `AnalysisView.swift`: Presents metrics, insights, score, and navigation controls (timeline and chips); allows scrubbing to key moments.
  - `HistoryView.swift`: Lists past sessions, supports navigation to details, and plays back associated videos.

- Utils
  - `FrameBuffer.swift`: Fixed‑size circular buffer for recent pose frames, optimized for constant‑time append and bounded memory.
  - Smoothing lives within `MetricsCalculator` in the MVP; a separate `SignalProcessor.swift` can be introduced later if needed.

## Interfaces & Contracts (plain language)

- `PoseProcessor`
  - Inputs: Camera frames or video files
  - Outputs: Ordered `PoseFrame`s with normalized coordinates and confidence values
  - Guarantees: Background execution for heavy work; consistent coordinate system; optional downsampling

- `SwingDetector`
  - Inputs: Time‑ordered `PoseFrame`s
  - Outputs: `PotentialSwing` candidates around velocity peaks (not final boundaries)
  - Guarantees: Bounded internal buffer; simple threshold‑based state machine; emits candidates with sufficient context for validation

- `GeminiValidator`
  - Inputs: `PotentialSwing`s (≈30 frames) and optional precomputed metrics
  - Outputs: Validated swings with refined start/end frames, swing type, confidence, and analysis insights
  - Guarantees: Uses 30‑frame context; network‑robust with retries and basic rate limiting; returns deterministic JSON schema

- `MetricsCalculator`
  - Inputs: Frames from a `SwingSegment`
  - Outputs: Kinematic metrics, simplified paths, and helper detections (e.g., contact point)
  - Guarantees: Smoothed values within configured ranges; deterministic results for identical inputs

- `VideoProcessor`
  - Inputs: Source descriptor (live or file)
  - Outputs: Collection of `AnalysisResult`s for detected swings
  - Guarantees: Orchestrates pipeline off the main thread; batches work for files; incremental accumulation during live capture; exposes progress via `ProcessingState` (pose extraction → metrics → detection → validation → analysis)

- Storage layer
  - Inputs: `AnalysisResult`s and associated media URLs
  - Outputs: Persisted sessions and shots retrievable for history views
  - Guarantees: Idempotent saves per session identifier; basic integrity checks for media files

## Data Flow Scenarios

- Live recording
  1. User starts capture; frames are produced by the camera.
  2. `PoseProcessor` converts frames to `PoseFrame`s on a background queue.
  3. `SwingDetector` ingests frames and monitors thresholds to find swing boundaries.
  4. When capture ends or a swing completes, a `SwingSegment` is finalized.
  5. `MetricsCalculator` computes metrics and insights for the segment.
  6. Results and the associated video clip are saved via storage modules.

- Video upload
  1. User selects a file; frames are sampled at a steady rate.
  2. `PoseProcessor` batch‑extracts pose frames.
  3. `SwingDetector` processes frames to detect swings.
  4. Each detected swing is analyzed; results are persisted for History.

## Performance & Resource Management

- Throughput: Optionally process every third frame in live mode to target ~10 fps effective pose estimation.
- Memory: Maintain a small rolling buffer (~three seconds of frames) for detection.
- Background work: Run pose detection and heavy analysis off the main thread.
- Batching: Handle uploaded videos in manageable chunks to keep memory stable.
- Storage hygiene: Support a video retention policy (e.g., delete items older than 30 days) and expose total storage used.

## Platform & Privacy

- Device: Vision body pose requires a real device; target iOS 14.0+ (VNDetectHumanBodyPoseRequest). iPhone 12 or newer recommended for performance.
- Privacy: Obtain user consent before sending frames for cloud analysis; downsample images (e.g., 480p) prior to upload; exclude PII; provide an option to disable cloud processing.

## Accessibility & UX Principles

- Target sizes: 44‑point minimum for primary taps; 56‑point timeline band.
- Redundant cues: Use text + shape, not color alone, for markers and chips.
- VoiceOver: `TimelineStrip` exposes adjustable previous/next, descriptive labels/values; chips provide full labels (e.g., type + score).
- Haptics: Provide selection feedback on timeline and chip changes.

## Error Handling & Reliability

- Detection timeouts and threshold validation to avoid false positives.
- Clear separation of recoverable (e.g., transient I/O) vs non‑recoverable errors.
- Persistence safeguards and basic media integrity checks.
- Minimal but useful logging around pipeline stages for diagnostics.

## Testing Strategy

- Unit tests: `SwingDetector` with synthetic or recorded pose sequences; metrics with known inputs.
- Integration: End‑to‑end runs with representative tennis videos.
- Performance: Multi‑minute clips to validate steady throughput.
- Memory: Extended live recording sessions to observe stability.


