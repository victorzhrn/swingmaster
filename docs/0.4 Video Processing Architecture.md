# Video Processing Architecture - Complete Technical Guide

## Executive Summary

The SwingMaster video processing pipeline transforms tennis swing videos into actionable coaching insights through a sophisticated multi-stage analysis system. The pipeline combines Apple's Vision framework for body pose detection, YOLO11 CoreML for object detection (tennis balls and rackets), custom swing detection algorithms, and AI validation to deliver comprehensive swing analysis.

## Video Processing File Architecture

```
swingmaster/
‚îú‚îÄ‚îÄ Core/                                   [Video Processing Pipeline]
‚îÇ   ‚îú‚îÄ‚îÄ VideoProcessor.swift               # Main orchestrator - coordinates entire pipeline
‚îÇ   ‚îú‚îÄ‚îÄ PoseProcessor.swift                # Vision framework - extracts body joints
‚îÇ   ‚îú‚îÄ‚îÄ TennisObjectDetector.swift         # YOLO11 - detects balls/rackets
‚îÇ   ‚îú‚îÄ‚îÄ SwingDetector.swift                # Identifies swing boundaries
‚îÇ   ‚îú‚îÄ‚îÄ MetricsCalculator.swift            # Computes kinematic metrics
‚îÇ   ‚îî‚îÄ‚îÄ GeminiValidator.swift              # AI validation of swings
‚îÇ
‚îú‚îÄ‚îÄ Managers/                               [Processing & Storage]
‚îÇ   ‚îú‚îÄ‚îÄ ProcessingManager.swift            # Singleton - manages concurrent processing
‚îÇ   ‚îú‚îÄ‚îÄ AnalysisStore.swift                # Persistence of analysis results
‚îÇ   ‚îî‚îÄ‚îÄ VideoStorage.swift                 # File management & thumbnails
‚îÇ
‚îú‚îÄ‚îÄ Models/                                 [Processing Data Structures]
‚îÇ   ‚îú‚îÄ‚îÄ PoseFrame.swift                    # Normalized pose data (17 joints)
‚îÇ   ‚îú‚îÄ‚îÄ ObjectDetection.swift              # YOLO detection results
‚îÇ   ‚îú‚îÄ‚îÄ SwingSegment.swift                 # Detected swing boundaries
‚îÇ   ‚îú‚îÄ‚îÄ AnalysisResult.swift               # Complete analysis package
‚îÇ   ‚îú‚îÄ‚îÄ Shot.swift                         # UI-friendly shot model
‚îÇ   ‚îú‚îÄ‚îÄ SegmentMetrics.swift               # Swing metrics data
‚îÇ   ‚îî‚îÄ‚îÄ ValidatedSwing.swift               # AI-validated swing data
‚îÇ
‚îú‚îÄ‚îÄ Utils/                                  [Processing Utilities]
‚îÇ   ‚îú‚îÄ‚îÄ TrajectoryComputer.swift           # On-demand trajectory computation
‚îÇ   ‚îî‚îÄ‚îÄ FrameBuffer.swift                  # Circular buffer for frames
‚îÇ
‚îî‚îÄ‚îÄ yolo11l.mlpackage/                     [ML Model]
    ‚îî‚îÄ‚îÄ (YOLO11 CoreML model ~50MB)        # Tennis object detection model
```

### File Interaction Map

```mermaid
graph TB
    subgraph "Entry Points"
        CV[ContentView]
        MV[MainView]
    end
    
    subgraph "Processing Layer"
        PM[ProcessingManager]
        VP[VideoProcessor]
        PP[PoseProcessor]
        TOD[TennisObjectDetector]
        SD[SwingDetector]
        MC[MetricsCalculator]
        GV[GeminiValidator]
    end
    
    subgraph "Storage Layer"
        SS[SessionStore]
        AS[AnalysisStore]
        VS[VideoStorage]
    end
    
    subgraph "UI Layer"
        AV[AnalysisView]
        TO[TrajectoryOverlay]
        TS[TimelineStrip]
        VPO[VideoProcessingOverlay]
    end
    
    CV --> PM
    MV --> SS
    PM --> VP
    VP --> PP
    VP --> TOD
    PP --> SD
    SD --> MC
    MC --> GV
    GV --> AS
    AS --> SS
    SS --> MV
    SS --> AV
    AV --> TO
    AV --> TS
    MV --> VPO
    
    style PM fill:#339af0
    style VP fill:#4A9B4E
    style AS fill:#F7DC6F
```

## System Overview

```mermaid
flowchart TB
    subgraph "Input Sources"
        CAM[üìπ Camera Recording]
        UPLOAD[üìÅ Video Upload]
    end
    
    subgraph "Processing Pipeline"
        PM[ProcessingManager<br/>Orchestrator]
        VP[VideoProcessor<br/>Main Pipeline]
        
        subgraph "Core Processing Stages"
            POSE[PoseProcessor<br/>Body Detection]
            OBJ[TennisObjectDetector<br/>Ball/Racket Detection]
            SWING[SwingDetector<br/>Motion Patterns]
            METRICS[MetricsCalculator<br/>Kinematics]
            VALID[GeminiValidator<br/>AI Validation]
        end
    end
    
    subgraph "Storage & UI"
        STORE[AnalysisStore<br/>Persistence]
        SESSION[SessionStore<br/>State Management]
        UI[AnalysisView<br/>Visualization]
    end
    
    CAM --> PM
    UPLOAD --> PM
    PM --> VP
    VP --> POSE
    VP --> OBJ
    POSE --> SWING
    SWING --> METRICS
    METRICS --> VALID
    VALID --> STORE
    STORE --> SESSION
    SESSION --> UI
    
    style VP fill:#4A9B4E,stroke:#333,stroke-width:2px,color:#fff
    style PM fill:#339af0,stroke:#333,stroke-width:2px,color:#fff
    style VALID fill:#F7DC6F,stroke:#333,stroke-width:2px
```

---

## Detailed Processing Flow

### Stage 1: Video Input & Session Creation

```mermaid
flowchart LR
    subgraph "User Action"
        REC[Record Video]
        UP[Upload Video]
    end
    
    subgraph "Session Creation"
        CREATE[Create Session<br/>Status: Pending]
        THUMB[Generate Thumbnail<br/>Async]
        QUEUE[Add to Processing Queue]
    end
    
    subgraph "Files Involved"
        F1[ContentView.swift]
        F2[CameraView.swift]
        F3[SessionStore.swift]
        F4[VideoStorage.swift]
    end
    
    REC --> CREATE
    UP --> CREATE
    CREATE --> THUMB
    CREATE --> QUEUE
    
    F1 -.-> CREATE
    F2 -.-> REC
    F3 -.-> CREATE
    F4 -.-> THUMB
```

**Key Points:**
- Session created immediately (non-blocking)
- Video appears in UI instantly with "Processing" status
- Thumbnail generation runs asynchronously
- Maximum 2 concurrent processing operations

**Files:**
- `ContentView.swift`: Handles video creation flow
- `CameraView.swift`: Records video with live overlays
- `SessionStore.swift`: Manages session state
- `VideoStorage.swift`: File management & thumbnails

---

### Stage 2: Pose & Object Extraction

```mermaid
flowchart TD
    subgraph "Video Analysis"
        VID[Video File<br/>Native FPS]
        FPS[Detect FPS<br/>& Orientation]
        
        subgraph "Parallel Processing"
            POSE[Pose Extraction<br/>Vision Framework]
            OBJ[Object Detection<br/>YOLO11 CoreML]
        end
        
        FRAMES[Frame-by-Frame<br/>Processing]
    end
    
    subgraph "Output Data"
        PF[PoseFrame Array<br/>17 body joints]
        OF[ObjectDetectionFrame Array<br/>Ball & Racket boxes]
    end
    
    subgraph "Files"
        F1[VideoProcessor.swift]
        F2[PoseProcessor.swift]
        F3[TennisObjectDetector.swift]
        F4[Models/PoseFrame.swift]
        F5[Models/ObjectDetection.swift]
    end
    
    VID --> FPS
    FPS --> FRAMES
    FRAMES --> POSE
    FRAMES --> OBJ
    POSE --> PF
    OBJ --> OF
    
    F1 -.-> FPS
    F2 -.-> POSE
    F3 -.-> OBJ
    F4 -.-> PF
    F5 -.-> OF
```

**Technical Details:**
- **FPS Detection**: Reads native video frame rate (typically 30fps for iOS)
- **Orientation Handling**: Detects portrait/landscape from video transform
- **Pose Extraction**: 
  - 17 joint points per frame (Vision framework)
  - Normalized coordinates (0-1)
  - Confidence scores per joint
- **Object Detection**:
  - YOLO11 model (~50MB)
  - Detects tennis balls and rackets
  - Bounding boxes with confidence scores
  - Runs on-device via CoreML

**Files:**
- `VideoProcessor.swift`: Orchestrates extraction (lines 38-77)
- `PoseProcessor.swift`: Vision framework integration
- `TennisObjectDetector.swift`: YOLO11 implementation
- `Models/PoseFrame.swift`: Pose data structure
- `Models/ObjectDetection.swift`: Detection results

---

### Stage 3: Swing Detection & Analysis

```mermaid
flowchart LR
    subgraph "Motion Analysis"
        CALC[Calculate Metrics<br/>Velocities & Angles]
        DETECT[Detect Swings<br/>Motion Peaks]
        SEGMENT[Extract Segments<br/>+0.5s padding]
    end
    
    subgraph "Detection Algorithm"
        VEL[Angular Velocity<br/>Threshold: 2.0 rad/s]
        PEAK[Find Peaks]
        WINDOW[30-frame window<br/>~1 second]
    end
    
    subgraph "Swing Data"
        PS[PotentialSwing<br/>Candidates]
        SEG[SwingSegment<br/>Padded frames]
    end
    
    subgraph "Files"
        F1[MetricsCalculator.swift]
        F2[SwingDetector.swift]
        F3[Models/SwingSegment.swift]
    end
    
    CALC --> DETECT
    DETECT --> SEGMENT
    VEL --> PEAK
    PEAK --> WINDOW
    WINDOW --> PS
    PS --> SEG
    
    F1 -.-> CALC
    F2 -.-> DETECT
    F3 -.-> SEG
```

**Algorithm Details:**
- **Metrics Calculation**:
  - Angular velocity from joint movements
  - Linear velocity tracking
  - Smoothing with 3-frame window
- **Swing Detection**:
  - State machine: Idle ‚Üí Active ‚Üí Cooldown
  - Threshold: 2.0 rad/s angular velocity
  - Minimum 10 frames for valid swing
- **Segment Padding**:
  - Adds 0.5s before/after swing
  - Captures approach and follow-through
  - Essential for trajectory visualization

**Files:**
- `MetricsCalculator.swift`: Kinematic computations
- `SwingDetector.swift`: Peak detection algorithm
- `Models/SwingSegment.swift`: Swing boundaries

---

### Stage 4: AI Validation & Classification

```mermaid
flowchart TD
    subgraph "Validation Pipeline"
        CAND[Potential Swings]
        VAL[GeminiValidator<br/>AI Analysis]
        
        subgraph "Validation Process"
            TYPE[Classify Type<br/>FH/BH/Serve]
            CONF[Confidence Score]
            REFINE[Refine Boundaries]
        end
    end
    
    subgraph "Output"
        VS[ValidatedSwing<br/>Type & Confidence]
        METRICS[SegmentMetrics<br/>Kinematics]
    end
    
    subgraph "Files"
        F1[GeminiValidator.swift]
        F2[Models/AnalysisResult.swift]
    end
    
    CAND --> VAL
    VAL --> TYPE
    TYPE --> CONF
    CONF --> REFINE
    
    REFINE --> VS
    VS --> METRICS
    
    F1 -.-> VAL
    F2 -.-> VS
```

**Validation Features:**
- **AI Classification**: Gemini API validates swing type
- **Confidence Scoring**: 0.0 to 1.0 confidence
- **Boundary Refinement**: Adjusts start/end frames

**Files:**
- `GeminiValidator.swift`: AI validation logic
- `Models/AnalysisResult.swift`: Final results

---

### Stage 5: Results Storage & UI Presentation

```mermaid
flowchart LR
    subgraph "Data Packaging"
        RES[AnalysisResult<br/>Complete Data]
        SHOT[Shot Model<br/>UI-Friendly]
        TRAJ[Trajectory Data<br/>Padded Frames]
    end
    
    subgraph "Storage"
        STORE[AnalysisStore<br/>UserDefaults]
        PERSIST[Persisted Analysis<br/>JSON Encoded]
    end
    
    subgraph "UI Components"
        TIMELINE[TimelineStrip<br/>Shot Navigation]
        OVERLAY[TrajectoryOverlay<br/>Motion Paths]
        METRICS_UI[Metrics Display<br/>Stats]
    end
    
    subgraph "Files"
        F1[ProcessingManager.swift]
        F2[AnalysisStore.swift]
        F3[AnalysisView.swift]
        F4[TrajectoryOverlay.swift]
    end
    
    RES --> SHOT
    SHOT --> STORE
    STORE --> PERSIST
    
    PERSIST --> TIMELINE
    PERSIST --> OVERLAY
    PERSIST --> METRICS_UI
    
    F1 -.-> RES
    F2 -.-> STORE
    F3 -.-> TIMELINE
    F4 -.-> OVERLAY
```

**Storage Strategy:**
- **AnalysisResult**: Complete analysis with padded frames
- **Shot Model**: Simplified for UI with metrics
- **Persistence**: UserDefaults (MVP), Core Data (future)
- **Trajectory Data**: Stored for on-demand computation

**Files:**
- `ProcessingManager.swift`: Results packaging (lines 86-110)
- `AnalysisStore.swift`: Persistence layer
- `AnalysisView.swift`: Main analysis UI
- `TrajectoryOverlay.swift`: Motion visualization

---

## Processing States & User Feedback

```mermaid
stateDiagram-v2
    [*] --> Pending: Session Created
    Pending --> ExtractingPoses: Start Processing
    
    ExtractingPoses --> DetectingObjects: Poses Complete (50%)
    DetectingObjects --> CalculatingMetrics: Objects Complete (100%)
    
    CalculatingMetrics --> DetectingSwings: Metrics Ready
    DetectingSwings --> ValidatingSwings: Peaks Found
    
    ValidatingSwings --> Complete: All Valid
    ValidatingSwings --> Failed: No Valid Swings
    
    Complete --> [*]: Show Analysis
    Failed --> Retry: User Action
    Retry --> Pending
    
    note right of ExtractingPoses
        Progress: 0-50%
        "Detecting motion"
    end note
    
    note right of DetectingObjects
        Progress: 50-100%
        "Finding objects"
    end note
    
    note right of ValidatingSwings
        "Validating 2/5"
        Shows count
    end note
```

**Status Messages:**
- `Pending`: "Preparing..."
- `ExtractingPoses`: "Detecting motion" (0-50% progress)
- `DetectingObjects`: "Finding objects" (50-100% progress)
- `CalculatingMetrics`: "Calculating metrics"
- `DetectingSwings`: "Finding swings"
- `ValidatingSwings`: "Validating 2/5" (shows progress)
- `Complete`: "Ready"
- `Failed`: "Failed: [error]" with retry option

---

## Key Technical Components

### 1. Frame Rate Handling
```swift
// VideoProcessor.swift - Dynamic FPS detection
private func getVideoFPS(from url: URL) -> Double? {
    let asset = AVAsset(url: url)
    guard let videoTrack = asset.tracks(withMediaType: .video).first else {
        return nil
    }
    return Double(videoTrack.nominalFrameRate)  // Native FPS
}
```

### 2. Orientation Detection
```swift
// VideoProcessor.swift - Handle portrait/landscape
private func getVideoOrientation(from url: URL) -> CGImagePropertyOrientation {
    // Analyzes video transform matrix
    // Maps to correct orientation for processing
}
```

### 3. Segment Padding
```swift
// VideoProcessor.swift - Extract with padding
private func extractPaddedSegmentData(
    swing: ValidatedSwing,
    allPoseFrames: [PoseFrame],
    allObjectFrames: [ObjectDetectionFrame],
    paddingSeconds: Double = 0.5  // ¬± 0.5 seconds
)
```

### 4. Concurrent Processing
```swift
// ProcessingManager.swift - Queue management
private let maxConcurrentProcessing = 2
private var pendingQueue: [(Session, URL)] = []
```

---

## Data Models & Flow

### Core Data Structures

```mermaid
classDiagram
    class PoseFrame {
        +timestamp: TimeInterval
        +joints: Dictionary
        +confidences: Dictionary
    }
    
    class ObjectDetectionFrame {
        +timestamp: TimeInterval
        +racket: RacketDetection?
        +ball: BallDetection?
    }
    
    class SwingSegment {
        +startTime: Double
        +endTime: Double
        +frames: [PoseFrame]
    }
    
    class AnalysisResult {
        +segment: SwingSegment
        +swingType: ShotType
        +segmentMetrics: SegmentMetrics
        +objectFrames: [ObjectDetectionFrame]
    }
    
    class Shot {
        +id: UUID
        +time: Double
        +startTime: Double
        +endTime: Double
        +type: ShotType
        +paddedPoseFrames: [PoseFrame]
        +paddedObjectFrames: [ObjectDetectionFrame]
    }
    
    PoseFrame --> SwingSegment
    ObjectDetectionFrame --> AnalysisResult
    SwingSegment --> AnalysisResult
    AnalysisResult --> Shot
```

---

## Performance Optimizations

### 1. Memory Management
- **Frame Buffering**: Fixed-size circular buffers
- **Segment Extraction**: Only relevant frames kept
- **Lazy Loading**: Trajectories computed on-demand

### 2. Processing Efficiency
- **Native FPS**: Uses video's actual frame rate
- **Parallel Processing**: Pose and object detection run together
- **Queue Management**: Max 2 concurrent videos
- **Background Execution**: Non-blocking UI

### 3. Storage Strategy
- **Padded Frames**: ¬±0.5s for full motion capture
- **Compressed Storage**: UserDefaults with JSON encoding
- **Thumbnail Caching**: Async generation and persistence

---

## Error Handling & Recovery

### Error Types & Recovery

| Error Type | Recovery Strategy | User Feedback |
|------------|------------------|---------------|
| Pose Detection Fail | Retry with lower FPS | "Motion detection unavailable" |
| Object Detection Fail | Continue without objects | "Ball/racket tracking unavailable" |
| No Swings Found | Show video only | "No swings detected" |
| Validation Timeout | Skip validation | "Using basic analysis" |
| Storage Full | Clear old sessions | "Storage limit reached" |

### Retry Mechanism
```swift
// ProcessingManager.swift
func retryProcessing(for session: Session, sessionStore: SessionStore) {
    guard session.retryCount < session.maxRetries else { return }
    // Exponential backoff retry logic
}
```

---

## Quick Reference Guide

### File Responsibilities

| Component | File | Primary Function |
|-----------|------|------------------|
| Orchestration | `ProcessingManager.swift` | Queue management, state updates |
| Main Pipeline | `VideoProcessor.swift` | Coordinates all analysis stages |
| Pose Detection | `PoseProcessor.swift` | Vision framework, body joints |
| Object Detection | `TennisObjectDetector.swift` | YOLO11 ball/racket detection |
| Swing Detection | `SwingDetector.swift` | Motion pattern analysis |
| Metrics | `MetricsCalculator.swift` | Kinematic calculations |
| Validation | `GeminiValidator.swift` | AI swing classification |
| Storage | `AnalysisStore.swift` | Result persistence |
| UI | `AnalysisView.swift` | Result visualization |

### Processing Timeline

```mermaid
gantt
    title Video Processing Timeline
    dateFormat X
    axisFormat %s
    
    section Recording
    Record Video         :0, 5
    
    section Processing
    Create Session       :5, 1
    Extract Poses        :6, 3
    Detect Objects       :8, 2
    Calculate Metrics    :10, 1
    Detect Swings        :11, 1
    Validate Swings      :12, 2
    
    section Storage
    Package Results      :14, 1
    Save to Store        :15, 1
    
    section UI
    Update Status        :5, 11
    Show Analysis        :16, 1
```

---

## Conclusion

The SwingMaster video processing architecture represents a sophisticated pipeline that transforms raw video into actionable tennis coaching insights. By combining on-device AI (Vision + YOLO11), custom motion algorithms, and cloud validation, the system delivers professional-grade analysis while maintaining responsive performance and user privacy.

The architecture's strength lies in its:
- **Non-blocking design**: Users see immediate feedback
- **Modular pipeline**: Each stage can be independently improved
- **Intelligent caching**: Trajectories computed on-demand
- **Robust error handling**: Graceful degradation and retry logic
- **Scalable storage**: From UserDefaults (MVP) to Core Data (future)

This document serves as the authoritative reference for understanding, maintaining, and extending the video processing system.