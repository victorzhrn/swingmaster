# Tennis App - Phased Implementation Plan

## Overview
Build a fully functional tennis coaching app with mock data in 5 progressive phases. Each phase delivers testable functionality that builds toward the complete experience.

---

## Phase 1: Static UI Shell & Navigation
**Duration:** 4-6 hours  
**Goal:** Create all screens with navigation flow

### Components to Build

#### 1. App Structure
```swift
TennisApp.swift
├── ContentView.swift (navigation controller)
├── CameraView.swift (placeholder camera)
├── HistoryView.swift (list of sessions)
└── AnalysisView.swift (video + insights)
```

#### 2. Navigation System
```swift
enum Screen {
    case camera
    case history
    case analysis(session: MockSession)
}

@State private var currentScreen: Screen = .camera
```

#### 3. Mock Data Models
```swift
struct MockSession {
    let id = UUID()
    let date: String
    let shotCount: Int
    let videoURL: String // placeholder
    let thumbnail: String // SF Symbol or color
}

struct MockShot {
    let time: Double // seconds into video
    let type: ShotType // forehand/backhand
    let score: Float // 0-10
    let issue: String // "Late contact"
}
```

#### 4. UI Components
- **CameraView:** Black rectangle with camera icon, three buttons at bottom
- **HistoryView:** List with 5 hardcoded sessions
- **AnalysisView:** Video placeholder + static timeline + insight card

### Mock Data Provider
```swift
class MockDataProvider {
    static let sessions = [
        MockSession(date: "Today 2:30 PM", shotCount: 5, ...),
        MockSession(date: "Yesterday", shotCount: 3, ...),
        MockSession(date: "Jan 21", shotCount: 8, ...)
    ]
    
    static let sampleShots = [
        MockShot(time: 0.5, type: .forehand, score: 6.2, issue: "Late contact"),
        MockShot(time: 2.1, type: .backhand, score: 7.8, issue: "Good form"),
        MockShot(time: 3.8, type: .forehand, score: 5.9, issue: "Poor follow-through")
    ]
}
```

### Testing Checklist
- [x] App launches to camera view
- [x] Can navigate to history
- [x] Can tap session to see analysis
- [x] Back buttons work correctly
- [ ] UI matches design specs

---

## Phase 2: Live Camera & Recording States
**Duration:** 6-8 hours  
**Goal:** Real camera feed with recording functionality

### Components to Build

#### 1. Camera Manager
```swift
class CameraManager: ObservableObject {
    @Published var isRecording = false
    @Published var recordingTime = 0.0
    @Published var permissionGranted = false
    
    private var captureSession: AVCaptureSession?
    private var videoOutput: AVCaptureMovieFileOutput?
    
    func startRecording() { }
    func stopRecording() { }
    func setupCamera() { }
}
```

#### 2. Recording States
```swift
enum RecordingState {
    case idle
    case recording(elapsed: TimeInterval)
    case processing
    case complete(videoURL: URL)
}
```

#### 3. Vision Skeleton Overlay
```swift
// Phase 2: Static skeleton image overlay
// Phase 5: Real Vision framework integration
struct SkeletonOverlay: View {
    var body: some View {
        Image(systemName: "figure.walk")
            .resizable()
            .opacity(0.3)
    }
}
```

#### 4. Record Button Component
```swift
struct RecordButton: View {
    @Binding var state: RecordingState
    
    var body: some View {
        // 72pt circle
        // White → Red when recording
        // Pulse animation
    }
}
```

### Mock Behavior
- Record for max 10 seconds (auto-stop)
- Show processing for 2 seconds after recording
- Navigate to analysis with recorded video
- Mock detection returns 3 predetermined swings

### Testing Checklist
- [x] Camera permission request works
- [x] Start/Pause/Resume button updates label and color
- [x] Timer shows during recording
- [x] Auto-stops at 10 seconds
- [ ] Processing state appears
- [ ] Navigates to analysis on END
- [x] Upload/History buttons hidden during active session

---

## Phase 3: Dynamic Analysis View
**Duration:** 8-10 hours  
**Goal:** Full video playback with synchronized insights

### Components to Build

#### 1. Video Player Component
```swift
struct VideoPlayerView: UIViewControllerRepresentable {
    let url: URL
    @Binding var currentTime: Double
    @Binding var isPlaying: Bool
    
    // AVPlayer with time observer
    // Scrubbing support
    // Play/pause controls
}
```

#### 2. Timeline Component
```swift
struct TimelineView: View {
    let shots: [MockShot]
    let duration: Double
    @Binding var currentTime: Double
    
    var body: some View {
        // Horizontal stack of shot markers
        // Colored dots (green/yellow/red)
        // Labels (FH/BH + score)
        // Tap to jump to shot
    }
}
```

#### 3. Dynamic Insight Card
```swift
struct InsightCard: View {
    let currentShot: MockShot?
    
    var body: some View {
        // Updates based on video position
        // Shows shot type, score, issue
        // Animated transitions
    }
}
```

#### 4. Mock Swing Detector
```swift
class MockSwingDetector {
    static func detectSwings(in video: URL) -> [MockShot] {
        // Return predetermined shots based on video length
        let duration = getVideoDuration(video)
        return [
            MockShot(time: duration * 0.2, type: .forehand, ...),
            MockShot(time: duration * 0.5, type: .backhand, ...),
            MockShot(time: duration * 0.8, type: .forehand, ...)
        ]
    }
}
```

### Visual Overlays
```swift
struct VideoOverlay: View {
    let currentShot: MockShot?
    
    var body: some View {
        if let shot = currentShot {
            // Red dot at contact point
            // Green dot for ideal position
            // Arrow showing correction
        }
    }
}
```

### Testing Checklist
- [ ] Video plays smoothly
- [ ] Timeline markers at correct positions
- [ ] Insights update as video plays
- [ ] Can tap timeline to jump to shots
- [ ] Visual overlays appear at right time
- [ ] Auto-pause on critical issues

---

## Phase 4: Upload & Persistence
**Duration:** 4-6 hours  
**Goal:** Complete user flows with data persistence

### Components to Build

#### 1. Video Upload Handler
```swift
struct VideoUploader: View {
    @State private var showingPicker = false
    @State private var processingProgress = 0.0
    
    func processUploadedVideo(_ url: URL) {
        // Show progress for 3 seconds
        // Run mock detection
        // Save to history
        // Navigate to analysis
    }
}
```

#### 2. Session Storage
```swift
class SessionStore: ObservableObject {
    @Published var sessions: [MockSession] = []
    
    init() {
        loadFromUserDefaults()
    }
    
    func save(_ session: MockSession) {
        sessions.insert(session, at: 0)
        saveToUserDefaults()
    }
    
    func delete(_ session: MockSession) { }
}
```

#### 3. Thumbnail Generator
```swift
extension URL {
    func generateThumbnail() -> UIImage? {
        let asset = AVAsset(url: self)
        let generator = AVAssetImageGenerator(asset: asset)
        // Get frame at 1 second
        return thumbnail
    }
}
```

### Data Flow
```
Record/Upload → Process → Generate Thumbnail → Save Session → Show in History
```

### Testing Checklist
- [ ] Can upload video from photo library
- [ ] Progress bar during processing
- [ ] New sessions appear in history
- [ ] Thumbnails generate correctly
- [ ] Sessions persist across app launches
- [ ] Can delete sessions

---

## Phase 5: Polish & Production Ready
**Duration:** 4-6 hours  
**Goal:** Complete UX with all edge cases handled

### Components to Polish

#### 1. Loading States
```swift
struct LoadingView: View {
    let message: String
    var body: some View {
        // < 1s: Nothing
        // 1-3s: Spinner
        // > 3s: Message
    }
}
```

#### 2. Error Handling
```swift
enum AppError {
    case noSwingsDetected
    case cameraPermissionDenied
    case uploadFailed
    case processingFailed
    
    var userMessage: String { }
    var recoveryAction: String { }
}
```

#### 3. Empty States
```swift
struct EmptyStateView: View {
    let type: EmptyStateType
    
    var body: some View {
        // Icon + Message + Action button
        // "No sessions yet. Record your first swing!"
    }
}
```

#### 4. Animations
```swift
// Spring animations throughout
.animation(.spring(response: 0.3, dampingFraction: 0.8), value: state)

// Haptic feedback
UIImpactFeedbackGenerator(style: .medium).impactOccurred()

// Button press states
.scaleEffect(isPressed ? 0.95 : 1.0)
```

#### 5. Share Functionality
```swift
struct ShareSheet: UIViewControllerRepresentable {
    let video: URL
    let insights: [String]
    
    // Create shareable video with overlay
    // Include coaching tips as text
}
```

### Edge Cases to Handle
- No swings detected → Show helpful message
- Camera permission denied → Settings prompt
- Video too short/long → Guidance
- Network issues (if using Gemini) → Fallback to local
- Storage full → Warning

### Testing Checklist
- [ ] All loading states appear correctly
- [ ] Errors show helpful recovery options
- [ ] Empty states guide user action
- [ ] Animations feel smooth
- [ ] Share creates branded video
- [ ] App feels polished and complete

---

## File Structure

```
TennisApp/
├── App/
│   └── TennisApp.swift
├── Views/
│   ├── CameraView.swift
│   ├── AnalysisView.swift
│   └── HistoryView.swift
├── Components/
│   ├── RecordButton.swift
│   ├── VideoPlayer.swift
│   ├── TimelineView.swift
│   ├── InsightCard.swift
│   └── VideoOverlay.swift
├── Models/
│   ├── Session.swift
│   ├── Shot.swift
│   └── SwingAnalysis.swift
├── Managers/
│   ├── CameraManager.swift
│   ├── VideoProcessor.swift
│   └── SessionStore.swift
├── Mock/
│   ├── MockDataProvider.swift
│   ├── MockSwingDetector.swift
│   └── MockAnalyzer.swift
└── Utils/
    ├── VideoUtils.swift
    └── Extensions.swift
```

---

## Success Metrics

### Phase 1 Complete When:
- All three screens exist and are navigable
- Mock data displays correctly

### Phase 2 Complete When:
- Can record real video
- States transition smoothly

### Phase 3 Complete When:
- Video analysis feels real
- Insights sync with playback

### Phase 4 Complete When:
- Full user journey works
- Data persists properly

### Phase 5 Complete When:
- No broken states
- Feels professional
- Ready for real users

---

## Migration to Real Implementation

When ready to add real swing detection:

1. **Replace MockSwingDetector** with real Vision framework implementation
2. **Swap MockAnalyzer** with Gemini API calls
3. **Keep all UI components unchanged**
4. **Add network layer for API communication**

The mock layer acts as a contract - real implementations must match the same interfaces.